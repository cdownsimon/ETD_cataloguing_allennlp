{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.matrix_attention.linear_matrix_attention import LinearMatrixAttention\n",
    "from allennlp.nn import util\n",
    "\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention = LinearMatrixAttention(800, 800, 'x,y,x*y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 69])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = th.rand(1,1,800)\n",
    "y = th.rand(1,69,800)\n",
    "self_attention(x,y).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = th.randn(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2188, -0.6998,  1.1127,  0.3072,  1.0043],\n",
       "        [ 0.6953,  0.4697, -0.0422,  0.3413, -1.2633],\n",
       "        [ 1.5753,  0.4542,  1.2470,  1.1029, -0.4689]])"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_labels = th.tensor([[1,1,1,0,0],[0,0,0,1,0],[1,0,1,0,0]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.2188, -0.6998,  1.1127,  0.3072,  1.0043],\n",
       "         [ 0.6953,  0.4697, -0.0422,  0.3413, -1.2633],\n",
       "         [ 1.5753,  0.4542,  1.2470,  1.1029, -0.4689]]),\n",
       " tensor([[ 1.,  1.,  1.,  0.,  0.],\n",
       "         [ 0.,  0.,  0.,  1.,  0.],\n",
       "         [ 1.,  0.,  1.,  0.,  0.]]))"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions,gold_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.6998, -1.2633, -0.4689])"
      ]
     },
     "execution_count": 713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 5\n",
    "top_k = predictions.topk(k)[0][:,k-1]\n",
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = torch.ge(predictions,top_k.unsqueeze(1).expand(predictions.size(0),predictions.size(1))).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((((gold_labels + predictions) >= 2).sum(1).float()/gold_labels.sum(1).float()).sum()/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.rand(26,800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 756.,  764.,  265.,  260.,  380.,  516.,  389.,  331.,  366.,\n",
       "         317.,  595.,  628.,  428.,  796.,    6.,  347.,  729.,  207.,\n",
       "          61.,  255.,  614.,  244.,  109.,  711.,  317.,  320.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.max(-1)[1].float().squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = th.tensor([[1,0,0],[1,0,1],[0,1,1],[0,1,0]]).float()\n",
    "predict = th.tensor([[1,0,0],[0,0,1],[1,0,0],[0,0,1]]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(true*predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(true*predict)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 1.,  1.,  0.,  0.]), tensor([ 1.,  0.,  1.,  0.]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true[:,0],predict[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = true[:,0]\n",
    "p0 = predict[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t0*p0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1-t0)*(1-p0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-(t0*p0)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p0-t0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1-t0)*p0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(t0*(1-p0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  1.],\n",
       "        [ 0.,  1.,  1.],\n",
       "        [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5000)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((true*predict).sum(1)/true.sum(1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.],\n",
       "        [ 1.,  0.,  1.],\n",
       "        [ 0.,  1.,  1.],\n",
       "        [ 0.,  1.,  0.]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.],\n",
       "        [ 1.,  0.,  0.],\n",
       "        [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  0.,  0.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true[:,l] * predict[:,l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=0\n",
    "(true[:,l] * predict[:,l]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(true*predict).sum(0)[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l=2\n",
    "((1-true[:,l]) * (1- predict[:,l])).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((1-true)*(1-predict)).sum(0)[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "_true_positives = (true*predict).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "_false_positives = (true*predict).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = _true_positives / (_false_positives + 1e-13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = 2. * ((tmp * tmp) / (tmp + tmp + 1e-13))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.6667)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules import FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = FeedForward(5,2,10,'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = []\n",
    "for n, param in linear.named_parameters():\n",
    "    if 'weight' in n:\n",
    "        params.append(param)\n",
    "target_param = params[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1179, -0.2996,  0.1698,  0.2341,  0.1861,  0.2195, -0.0739,  0.1006,\n",
       "         -0.1433,  0.1459],\n",
       "        [ 0.1558, -0.1414, -0.0286, -0.3127, -0.2545,  0.0639,  0.2007, -0.0902,\n",
       "         -0.0379,  0.0910],\n",
       "        [-0.1573,  0.2527,  0.0598, -0.0828, -0.2393, -0.2237,  0.1925, -0.0457,\n",
       "         -0.2069, -0.2214],\n",
       "        [ 0.1934,  0.2431,  0.1339,  0.0987, -0.2624,  0.3061, -0.0556, -0.2501,\n",
       "          0.1696, -0.1801],\n",
       "        [ 0.1682,  0.0968,  0.0831,  0.2584,  0.1386, -0.0639,  0.2007,  0.0686,\n",
       "         -0.1568, -0.2099],\n",
       "        [-0.0444,  0.0677,  0.1154,  0.1922,  0.3126, -0.2419, -0.1068,  0.2502,\n",
       "          0.1152,  0.1067],\n",
       "        [ 0.2451, -0.1460, -0.2428,  0.1853, -0.2830,  0.0117,  0.1820,  0.1565,\n",
       "          0.2472,  0.3086],\n",
       "        [ 0.2736, -0.2389,  0.2741,  0.1414,  0.0016,  0.3063, -0.2257,  0.2314,\n",
       "          0.1119,  0.0261],\n",
       "        [ 0.2017, -0.2562, -0.1686,  0.2812,  0.2450, -0.1068, -0.2439,  0.0668,\n",
       "         -0.0094, -0.1221],\n",
       "        [ 0.3132,  0.0466,  0.1576, -0.1501, -0.2074, -0.1885, -0.1106,  0.2202,\n",
       "         -0.1880, -0.3103]], requires_grad=True)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1558, -0.1414, -0.0286, -0.3127, -0.2545,  0.0639,  0.2007, -0.0902,\n",
       "         -0.0379,  0.0910],\n",
       "        [ 0.1558, -0.1414, -0.0286, -0.3127, -0.2545,  0.0639,  0.2007, -0.0902,\n",
       "         -0.0379,  0.0910],\n",
       "        [ 0.1558, -0.1414, -0.0286, -0.3127, -0.2545,  0.0639,  0.2007, -0.0902,\n",
       "         -0.0379,  0.0910],\n",
       "        [ 0.1558, -0.1414, -0.0286, -0.3127, -0.2545,  0.0639,  0.2007, -0.0902,\n",
       "         -0.0379,  0.0910],\n",
       "        [ 0.1934,  0.2431,  0.1339,  0.0987, -0.2624,  0.3061, -0.0556, -0.2501,\n",
       "          0.1696, -0.1801],\n",
       "        [-0.0444,  0.0677,  0.1154,  0.1922,  0.3126, -0.2419, -0.1068,  0.2502,\n",
       "          0.1152,  0.1067]], grad_fn=<TakeBackward>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_param[[1,1,1,1,3,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8165, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.norm(target_param[[1,3,5]]-target_param[[5,7,1]],2,1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = th.optim.SGD(linear.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0126,  0.2827, -0.4353,  0.0226,  0.0056],\n",
       "        [-0.0643,  0.3521, -0.2954, -0.3986, -0.0568],\n",
       "        [-0.2083, -0.2609,  0.0186, -0.1921,  0.1349],\n",
       "        [ 0.3564,  0.4360,  0.0539,  0.0931,  0.1806],\n",
       "        [ 0.2896,  0.4071,  0.2728,  0.0194,  0.2296],\n",
       "        [-0.1640,  0.2470,  0.3195, -0.4202, -0.0181],\n",
       "        [ 0.0951, -0.3350, -0.3095,  0.1322, -0.1912],\n",
       "        [ 0.2780,  0.0138, -0.1370,  0.4208, -0.0639],\n",
       "        [ 0.1533, -0.3238, -0.2623,  0.3911, -0.1782],\n",
       "        [ 0.4145, -0.2262,  0.3164, -0.2626,  0.0993]], requires_grad=True)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4545, grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.norm(params[0][1][0]-params[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = th.nn.LSTM(10,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1670,  0.2917,  0.2211,  0.0153,  0.4960, -0.2319,  0.2642, -0.9624,\n",
       "           0.3835, -0.8068],\n",
       "         [-0.7509, -0.2114, -0.7882, -0.5555,  0.8680, -0.0634,  0.4944,  0.8323,\n",
       "           0.0534, -0.2827],\n",
       "         [ 0.9128, -0.2959,  0.7704,  0.2507, -0.2608,  0.6896,  0.7365, -0.7078,\n",
       "          -0.2602,  0.5349],\n",
       "         [-0.9607,  0.5065,  0.4523, -0.2891, -0.9092,  0.7098,  0.9130, -0.1830,\n",
       "           0.6092,  0.7942]], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.5741],\n",
       "         [ 0.1430],\n",
       "         [ 0.6417],\n",
       "         [ 0.7707]], requires_grad=True), Parameter containing:\n",
       " tensor([0.9047, 0.3792, 0.2942, 0.3699], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.4149, -0.7786, -0.0173,  0.3669], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.8633],\n",
       "         [ 0.8483],\n",
       "         [-0.2649],\n",
       "         [ 0.4731]], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.1533],\n",
       "         [ 0.9004],\n",
       "         [ 0.6605],\n",
       "         [ 0.1624]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.6038, -0.6861,  0.4161, -0.0979], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.9451, -0.6624, -0.8092, -0.5897], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.4281],\n",
       "         [ 0.5353],\n",
       "         [-0.8739],\n",
       "         [ 0.2798]], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.7095],\n",
       "         [-0.0504],\n",
       "         [-0.1716],\n",
       "         [-0.5098]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.9872,  0.1007,  0.1633, -0.1517], requires_grad=True), Parameter containing:\n",
       " tensor([-0.1431,  0.1228, -0.0881, -0.2916], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.3091],\n",
       "         [-0.5204],\n",
       "         [ 0.2758],\n",
       "         [-0.4490]], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.2117],\n",
       "         [-0.9534],\n",
       "         [ 0.1476],\n",
       "         [ 0.8099]], requires_grad=True), Parameter containing:\n",
       " tensor([0.9898, 0.5595, 0.4743, 0.2504], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.0499,  0.8529, -0.8394, -0.4879], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.9925],\n",
       "         [ 0.9087],\n",
       "         [-0.4523],\n",
       "         [ 0.2990]], requires_grad=True), Parameter containing:\n",
       " tensor([[0.8729],\n",
       "         [0.7450],\n",
       "         [0.0191],\n",
       "         [0.6497]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.9407,  0.1918, -0.6173,  0.2344], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.2763,  0.2712, -0.3831,  0.2040], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.6890],\n",
       "         [ 0.7382],\n",
       "         [-0.9457],\n",
       "         [-0.3514]], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.3318],\n",
       "         [-0.8303],\n",
       "         [-0.4432],\n",
       "         [-0.9718]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.6102,  0.7750,  0.2182, -0.3848], requires_grad=True), Parameter containing:\n",
       " tensor([-0.4272, -0.0380,  0.5343,  0.2763], requires_grad=True), Parameter containing:\n",
       " tensor([[0.4516],\n",
       "         [0.1860],\n",
       "         [0.4935],\n",
       "         [0.9205]], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.6025],\n",
       "         [ 0.6377],\n",
       "         [ 0.7437],\n",
       "         [-0.1945]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.8217,  0.1456, -0.2555,  0.7294], requires_grad=True), Parameter containing:\n",
       " tensor([0.0206, 0.3300, 0.2305, 0.7336], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.8197],\n",
       "         [-0.4646],\n",
       "         [-0.5581],\n",
       "         [-0.8749]], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.7240],\n",
       "         [ 0.1113],\n",
       "         [ 0.4801],\n",
       "         [-0.5581]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.7561, -0.3834, -0.4094,  0.4624], requires_grad=True), Parameter containing:\n",
       " tensor([-0.8844, -0.8634,  0.4935,  0.8264], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.3257],\n",
       "         [-0.2858],\n",
       "         [ 0.5069],\n",
       "         [ 0.5825]], requires_grad=True), Parameter containing:\n",
       " tensor([[ 0.2044],\n",
       "         [ 0.0705],\n",
       "         [-0.1345],\n",
       "         [-0.6384]], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.2559,  0.3554,  0.6024, -0.7722], requires_grad=True), Parameter containing:\n",
       " tensor([-0.6448,  0.2717, -0.2480, -0.5027], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.2337],\n",
       "         [ 0.0733],\n",
       "         [ 0.1845],\n",
       "         [ 0.2956]], requires_grad=True), Parameter containing:\n",
       " tensor([[-0.2962],\n",
       "         [-0.5117],\n",
       "         [ 0.6019],\n",
       "         [-0.2401]], requires_grad=True), Parameter containing:\n",
       " tensor([-0.5826, -0.5904, -0.0422, -0.3116], requires_grad=True), Parameter containing:\n",
       " tensor([ 0.2663, -0.7987, -0.5123, -0.6681], requires_grad=True)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in lstm.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for l,n in enumerate(hl):\n",
    "    y = th.zeros(n,5*len(hl))\n",
    "    y[:,l*5:(l+1)*5] = 1\n",
    "    t.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0:5,3:6]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.cat(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = th.randn(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2884, -0.6896,  1.4009, -0.0840],\n",
       "         [ 1.2884, -0.6896,  1.4009, -0.0840],\n",
       "         [ 1.2884, -0.6896,  1.4009, -0.0840],\n",
       "         [ 1.2884, -0.6896,  1.4009, -0.0840],\n",
       "         [ 1.2884, -0.6896,  1.4009, -0.0840]],\n",
       "\n",
       "        [[ 0.5904,  0.6352, -1.7919, -0.9090],\n",
       "         [ 0.5904,  0.6352, -1.7919, -0.9090],\n",
       "         [ 0.5904,  0.6352, -1.7919, -0.9090],\n",
       "         [ 0.5904,  0.6352, -1.7919, -0.9090],\n",
       "         [ 0.5904,  0.6352, -1.7919, -0.9090]],\n",
       "\n",
       "        [[-0.5692,  2.1354,  0.0221, -0.0875],\n",
       "         [-0.5692,  2.1354,  0.0221, -0.0875],\n",
       "         [-0.5692,  2.1354,  0.0221, -0.0875],\n",
       "         [-0.5692,  2.1354,  0.0221, -0.0875],\n",
       "         [-0.5692,  2.1354,  0.0221, -0.0875]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unsqueeze(1).expand(-1,5,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from my_library.losses.hierarchical_graph import HierarchicalGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/lcsh/sh_path.json','r') as d:\n",
    "    subject_paths = {}\n",
    "    lines = d.readlines()\n",
    "    for l in lines:\n",
    "        subject_paths.update(json.loads(l.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/lcsh/sh_hierarchy.json', \"r\") as hierarchy_file:\n",
    "    etd_hierarchy = json.load(hierarchy_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/all_etd_title_abstract_train_new.json', \"r\") as data_file:\n",
    "    etd_jsons = []\n",
    "    for line in data_file:\n",
    "        line = line.strip(\"\\n\")\n",
    "        if not line:\n",
    "            continue\n",
    "        etd_json = json.loads(line)\n",
    "        abstract = etd_json['etdAbstract']\n",
    "        labels = etd_json['lcsh']\n",
    "\n",
    "        etd_jsons.append((abstract,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47446"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lcsh = set(itertools.chain(*[l.keys() for _,l in etd_jsons]))\n",
    "len(lcsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_level = {}\n",
    "for l,sh in etd_hierarchy.items():\n",
    "    intersect = list(lcsh.intersection(sh))\n",
    "    if intersect:\n",
    "        groupby_level[int(l)-1] = intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "covered = list(itertools.chain(*[j for _,j in groupby_level.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "uncovered = (lcsh.difference(covered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47446"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_index = {}\n",
    "idx = 0\n",
    "for l,sh in groupby_level.items():\n",
    "    for i in sh:\n",
    "        class_index[i] = idx\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../class_index.json','w') as f:\n",
    "    json.dump(class_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/index/all_etd_title_abstract_class_index.json','r') as f:\n",
    "    class_to_idx = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2c = {i:c for c,i in c.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Science', 'Cognitive science', 'Artificial intelligence', 'Machine learning']"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_paths['Machine learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(etd_jsons[5][1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [subject_paths[l] for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ability',\n",
       " 'Art',\n",
       " 'Arts',\n",
       " 'Criminals',\n",
       " 'Culture',\n",
       " 'Human face recognition (Computer science)',\n",
       " 'Humanities',\n",
       " 'Identification photographs',\n",
       " 'Intellectual life',\n",
       " 'Learning ability',\n",
       " 'Learning and scholarship',\n",
       " 'Optical pattern recognition',\n",
       " 'Perceptrons',\n",
       " 'Persons',\n",
       " 'Photographs',\n",
       " 'Pictures',\n",
       " 'Self-organizing systems'}"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(itertools.chain(*paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,ls in etd_jsons:\n",
    "    labels = list(ls.keys())\n",
    "    paths = [subject_paths[l] for l in labels]\n",
    "    assert [class_to_idx[l] for l in set(itertools.chain(*paths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [list(l.keys()) for _,l in etd_jsons]\n",
    "all_labels = set(itertools.chain(*all_labels))\n",
    "all_labels = set(itertools.chain(*[subject_paths[l] for l in all_labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hand-to-hand fighting, Oriental']"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_paths['Hand-to-hand fighting, Oriental']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in mads_subjects_graph._roots:\n",
    "    subject_paths.update({r:[r]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53879"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_level = {}\n",
    "for l,sh in etd_hierarchy.items():\n",
    "    intersect = list(all_labels.intersection(sh))\n",
    "    if intersect:\n",
    "        groupby_level[int(l)-1] = intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_to_idx = {}\n",
    "idx = 0\n",
    "for l,sh in groupby_level.items():\n",
    "    for i in sh:\n",
    "        class_to_idx[i] = idx\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _,ls in etd_jsons:\n",
    "    labels = list(ls.keys())\n",
    "    paths = [subject_paths[l] for l in labels]\n",
    "    assert [class_to_idx[l] for l in set(itertools.chain(*paths))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53879"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(itertools.chain(*[j for _,j in groupby_level.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10255"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx['Hand-to-hand fighting, Oriental']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../test.json','w') as f:\n",
    "    json.dump(groupby_level, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../test.json','r') as f:\n",
    "    test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11102, 10222, 8014, 8058, 6240, 4298, 2539, 1479, 972, 572, 245, 129, 9]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(l) for _,l in test.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../Data/lcsh/parsed/authoritiessubjects.dict'\n",
    "with open(file_path,'rb') as d:\n",
    "    mads_subjects = pickle.load(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417721/417721 [00:01<00:00, 304994.56it/s]\n"
     ]
    }
   ],
   "source": [
    "missed = []\n",
    "missed_lcsh = []\n",
    "contained =[]\n",
    "connections = []\n",
    "for sb, details in tqdm(mads_subjects.items()):\n",
    "    narrowers = details['narrowers']\n",
    "    if narrowers:\n",
    "        cnt = len(narrowers)\n",
    "        for nar in narrowers:\n",
    "            if nar not in mads_subjects:\n",
    "                missed.append(nar)\n",
    "                cnt -= 1\n",
    "                continue\n",
    "            connections.append((details['authoritativeLabel'],mads_subjects[nar]['authoritativeLabel']))\n",
    "            contained.append(details['authoritativeLabel'])\n",
    "            contained.append(mads_subjects[nar]['authoritativeLabel'])\n",
    "        if cnt == 0:\n",
    "            missed_lcsh.append(details['authoritativeLabel'])\n",
    "    else:\n",
    "        missed_lcsh.append(details['authoritativeLabel'])\n",
    "root_n_leaf  = list(set(missed_lcsh).difference(contained))\n",
    "connections = {'link': connections, 'root_n_leaf': root_n_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mads_subjects_graph = HierarchicalGraph(directed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63027/63027 [00:00<00:00, 1056965.21it/s]\n"
     ]
    }
   ],
   "source": [
    "mads_subjects_graph.load(connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233727"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_nodes = list(mads_subjects_graph._nodes.keys())\n",
    "len(graph_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 417721/417721 [00:00<00:00, 1859521.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "417721"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mads_subjects_authoritativeLabel = [details['authoritativeLabel'] for sb, details in tqdm(mads_subjects.items())]\n",
    "len(mads_subjects_authoritativeLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncovered.intersection(graph_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncovered.difference(mads_subjects_authoritativeLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncovered.difference(missed_lcsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncovered.difference(contained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(uncovered.difference(root_n_leaf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Cold war' in mads_subjects_authoritativeLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Cold War' in mads_subjects_authoritativeLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i.lower() for i in uncovered]).difference([i.lower() for i in missed_lcsh+contained])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([i.lower() for i in uncovered]).difference([i.lower() for i in mads_subjects_authoritativeLabel]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416469"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(contained+missed_lcsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416469"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(mads_subjects_authoritativeLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(mads_subjects_authoritativeLabel).difference(list(mads_subjects_graph._nodes.keys())+missed_lcsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(mads_subjects_authoritativeLabel).difference(list(mads_subjects_graph._nodes.keys())+missed_lcsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233727"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(contained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353776"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(missed_lcsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(contained+missed_lcsh).difference(mads_subjects_authoritativeLabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(mads_subjects_authoritativeLabel).difference(contained+missed_lcsh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233727"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mads_subjects_graph._nodes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(mads_subjects_graph._nodes.keys()).intersection(set(root_n_leaf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182742"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(missed_lcsh).difference(mads_subjects_graph._nodes.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConfigurationError",
     "evalue": "\"In order to skip indexing, your labels must be integers. Found labels = ['Child development']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConfigurationError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-f607f8d81556>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMultiLabelField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip_indexing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/misc/projdata3/info_fil/finance/simon_test/allennlp_official/allennlp/allennlp/data/fields/multilabel_field.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, labels, label_namespace, skip_indexing, num_labels)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m                 raise ConfigurationError(\"In order to skip indexing, your labels must be integers. \"\n\u001b[0;32m---> 66\u001b[0;31m                                          \"Found labels = {}\".format(labels))\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"In order to skip indexing, num_labels can't be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConfigurationError\u001b[0m: \"In order to skip indexing, your labels must be integers. Found labels = ['Child development']\""
     ]
    }
   ],
   "source": [
    "MultiLabelField([label for label,value in labels.items() if value == 1],skip_indexing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentences = torch.randn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = encoded_sentences.unsqueeze(1).expand(-1, 13, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sentences = encoded_sentences.unsqueeze(0) if len(encoded_sentences.size()) < 2 else encoded_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8127, -1.5018,  0.1780, -0.6542,  1.0974,  1.0849,  0.2327,  1.0172,\n",
       "          1.1240, -0.6912]])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8533,  0.4190, -2.0767, -0.0345,  0.6630, -0.7116,  1.5221,\n",
       "           0.7992, -1.0465, -0.3173],\n",
       "         [-0.6149,  0.9646,  0.3574,  1.1369,  2.1833,  0.9439, -2.7625,\n",
       "           1.0525, -0.0339, -1.8345],\n",
       "         [ 0.8095, -0.5504, -0.2730, -0.9327,  0.8884, -1.0047,  0.0709,\n",
       "          -1.1145, -0.6126, -1.0040],\n",
       "         [-0.4275,  1.4740,  1.6313, -0.3532, -0.5005, -0.0942, -1.6845,\n",
       "           0.5843, -0.1975,  0.4605],\n",
       "         [ 0.5792, -1.4113, -0.3771, -0.4636, -0.2917, -1.4306,  0.9793,\n",
       "          -0.7659, -0.8269, -0.3076],\n",
       "         [ 0.8639, -1.4813, -1.0534, -0.0316, -0.4078, -1.0978,  0.1940,\n",
       "          -0.1055, -0.2257,  0.8761],\n",
       "         [-0.4007, -0.1054, -0.4576,  0.0587, -0.5834, -2.8705,  1.7095,\n",
       "          -2.5253, -0.5600, -1.8780],\n",
       "         [-0.0916,  0.4525, -0.4344,  0.7702, -0.3336,  0.0061,  0.4410,\n",
       "           0.5020,  1.9787,  0.8349],\n",
       "         [ 0.8058, -2.2734, -0.5170,  0.4205,  0.6850, -1.3153,  2.1278,\n",
       "           0.0507, -0.5713, -0.4724],\n",
       "         [-2.0789, -0.4287,  0.8910,  0.0215, -1.1284,  0.9739, -0.5581,\n",
       "           1.1910, -1.4022,  1.7863],\n",
       "         [-0.0517, -1.7080,  0.7533, -0.5152, -0.1819,  1.1709,  0.2803,\n",
       "           0.9416,  1.0650, -0.4134],\n",
       "         [-2.2963, -0.2260,  0.5261,  1.2114, -1.2216,  0.8044,  0.9269,\n",
       "          -0.2096, -0.9021, -0.0166],\n",
       "         [ 0.5139, -0.0946,  0.4919, -0.6781,  0.7307, -0.5236, -0.5699,\n",
       "           1.2727, -0.6638,  1.0263]],\n",
       "\n",
       "        [[-0.6869,  1.0328,  0.1451,  0.9924, -0.2513,  1.4701, -0.1578,\n",
       "          -1.2405, -0.4850, -1.4975],\n",
       "         [-0.0721, -0.8242, -1.0884,  0.3376,  1.2036,  0.9692,  0.4073,\n",
       "           0.9092, -0.0283, -0.7537],\n",
       "         [-0.5078, -1.1650, -0.4861, -1.4129,  0.5540,  2.0595,  0.8215,\n",
       "          -0.9009, -1.9122, -0.3688],\n",
       "         [-0.0155, -0.2553,  0.4005, -0.6113,  1.6710,  0.0337, -0.8708,\n",
       "          -2.4953, -1.8854,  0.9633],\n",
       "         [-0.7123, -1.8385, -2.1088, -0.2985,  0.0459,  0.9134, -0.1783,\n",
       "          -0.9327,  0.7999,  1.8288],\n",
       "         [ 2.1960,  0.8943,  0.7237, -0.9055, -0.6696,  0.5195,  0.1323,\n",
       "           0.1343, -1.3420,  0.0365],\n",
       "         [ 0.0833, -0.2976,  0.9501, -1.5266, -0.5259,  0.0504,  0.8282,\n",
       "          -0.1346,  0.9025,  1.4702],\n",
       "         [ 0.9396,  0.9046, -1.6221,  0.1365,  0.9351, -0.0046,  0.2397,\n",
       "           0.3324, -0.3390,  0.8564],\n",
       "         [ 0.5401, -0.0226, -0.3994,  0.4823,  1.1543, -0.4708,  1.9201,\n",
       "           0.7003, -0.2672,  0.4469],\n",
       "         [-0.6190,  1.5758,  0.4051, -0.9814,  0.8685,  0.4269, -1.1819,\n",
       "          -1.1218,  1.8805,  1.5152],\n",
       "         [ 1.1708, -0.4336, -0.3338, -0.2846,  0.5621, -0.3539,  1.5070,\n",
       "          -0.5618,  0.7741,  0.5419],\n",
       "         [ 0.7613,  1.1445, -0.3508,  0.8674,  0.0415, -0.0514,  3.3765,\n",
       "           0.2646, -1.5777,  0.2960],\n",
       "         [ 2.2604, -0.0663, -0.0501,  0.8773,  0.4897, -0.2203,  1.2558,\n",
       "           0.0123, -0.0590,  0.7235]]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,13,10)\n",
    "w = [torch.randn(i+1,10) for i in range(13)]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6059, -6.7942,  0.8046,  3.8361,  3.9413,  4.3066,  2.4927,  3.5499,\n",
       "          1.0587, -2.4760, -0.7733, -0.7845,  0.0579,  2.7780,  2.3800,  1.3649,\n",
       "         -1.5505,  3.3124, -0.1399,  5.7586, -1.6194,  2.9416, -1.8218,  6.2885,\n",
       "          0.7569, -2.7944,  5.4584, -9.3708,  3.1077,  5.0431,  0.0940, -4.0578,\n",
       "         -0.8638,  4.5924, -0.4655, -1.6509, -1.4189, -0.0906, -0.7262,  5.1204,\n",
       "          0.3162, -1.1249,  2.6144,  1.9246,  1.2589,  4.3415,  9.1092,  3.2742,\n",
       "          4.7613,  3.6194,  0.9449,  0.4045,  4.8451, -2.9840, -2.1515,  2.1143,\n",
       "         -2.6395, -0.2799,  0.3988, -1.3586,  2.8291,  0.3997,  2.3667,  5.7298,\n",
       "         -4.0207,  2.0423,  2.1108, -3.7583, -3.3623, -3.4064,  5.1331, -0.3764,\n",
       "         -3.4477,  6.2547, -1.7320,  2.1923, -5.0698,  0.6963,  2.2288,  3.2331,\n",
       "         -1.6346,  3.9578,  1.2025, -1.2038, -0.2823, -0.4072,  2.7594, -0.1961,\n",
       "         -2.2852,  2.0799,  3.4738],\n",
       "        [-0.3312,  0.1029,  2.8425,  5.0372,  7.8872, -1.5711,  4.1248, -1.0108,\n",
       "         -1.3150,  1.2805, -1.2835, -0.0230,  3.6639,  5.6173,  3.5873, -2.3458,\n",
       "          4.3535, -0.6270,  0.3595, -1.4621, -2.0927,  1.7139,  0.1843,  0.4564,\n",
       "          1.7498, -2.8020,  2.0698,  3.5446,  5.4008,  4.3256,  0.5736, -1.6036,\n",
       "          3.1898,  2.0587,  0.1730, -0.5904, -0.2831,  0.3936, -1.2221,  1.0840,\n",
       "         -2.3418, -0.9780,  1.7586,  4.8693,  2.8976,  2.6944, -1.6269, -3.2969,\n",
       "         -1.7726,  6.2159, -0.3996, -2.1557,  2.6792,  3.0002, -2.5420,  1.8990,\n",
       "          1.0065,  1.2010, -0.4190,  0.9425,  2.1295, -0.6882, -0.3103,  3.5292,\n",
       "         -0.3107,  3.8166, -4.7771, -0.3322,  4.4106,  1.6340,  1.0068, -1.6778,\n",
       "          6.1062,  1.7377, -3.1243,  5.1107, -1.8463,  1.2513, -1.0384, -4.1292,\n",
       "         -2.4315,  8.1022,  0.8879,  3.6873,  0.3572,  3.0908, -5.3799, -3.3032,\n",
       "          3.7503,  1.4242,  0.4460]])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.nn.functional.linear(x[:,i,:],w[i],None) for i in range(13)], dim=1) + torch.ones(91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7855, 0.4102, 0.1455, 0.6103, 0.5276],\n",
       "        [0.1901, 0.0534, 0.2029, 0.7552, 0.1263],\n",
       "        [0.0534, 0.8271, 0.0519, 0.6432, 0.1110]])"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3,5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5600)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x[:,[1,3,4,4,4,4,4,4]] - x[:,[3,3,3,3,3,3,3,3]]).pow(2).sum(1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 2), (3, 4)}"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([(1,2),(1,2),(3,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-373-fa523135fe44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "[3,2,1][-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "child_parent_pairs = []\n",
    "with open('./data/index/etd_debug_child_parents.csv','r') as f:\n",
    "    for l in f.readlines():\n",
    "        pair = l.strip().split(',')\n",
    "        child_parent_pairs.append((int(pair[0]),int(pair[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9586,  0.7083,  1.1294,  0.8688, -0.9867,  0.2612,  0.3218,  1.2775,\n",
       "          0.3404, -0.5256],\n",
       "        [ 0.1447, -0.0454,  2.1842, -0.8901, -0.6541,  0.7833, -0.8478,  0.6289,\n",
       "          1.2716,  1.1189],\n",
       "        [ 0.9744,  0.6664,  0.4691,  0.6247, -1.2273, -1.2953,  0.1572,  0.2920,\n",
       "          0.0888, -0.7402]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(3,10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 0., 1., 0., 1., 1., 0., 1.],\n",
       "        [0., 1., 1., 0., 1., 1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 1., 1., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = (torch.rand(3,10) > 0.5).float()\n",
    "y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.7140,  1.5113,  1.2477],\n",
       "         [ 0.9857,  0.5312,  0.2728],\n",
       "         [ 1.6699,  1.1535, -0.0951]]), tensor([[0, 2, 4],\n",
       "         [7, 6, 3],\n",
       "         [1, 5, 3]]))"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.topk(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 0]])"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tensor([[1,1,0]])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x.unsqueeze(0),x.unsqueeze(0)],dim=0).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.matrix_attention.linear_matrix_attention import LinearMatrixAttention\n",
    "from allennlp.nn import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = LinearMatrixAttention(10,10,'x,y,x*y,x/y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn(torch.cat([x.unsqueeze(0),x.unsqueeze(0)],dim=0),torch.cat([x.unsqueeze(0),x.unsqueeze(0)],dim=0)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6fcf9dfbd479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.seq2seq_encoders.multi_head_self_attention import MultiHeadSelfAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1])"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhattn = MultiHeadSelfAttention(1,10,10,10,1)\n",
    "mhattn(x.unsqueeze(0)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = util.masked_softmax(mhattn(x.unsqueeze(0)).transpose(1,2),mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.5000, 0.5000, 0.0000]]], grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33814086"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.3338*1.7140+0.3338*-0.0093+0.3325*-0.6944"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9586,  0.7083,  1.1294,  0.8688, -0.9867,  0.2612,  0.3218,  1.2775,\n",
       "          0.3404, -0.5256],\n",
       "        [ 0.1447, -0.0454,  2.1842, -0.8901, -0.6541,  0.7833, -0.8478,  0.6289,\n",
       "          1.2716,  1.1189],\n",
       "        [ 0.9744,  0.6664,  0.4691,  0.6247, -1.2273, -1.2953,  0.1572,  0.2920,\n",
       "          0.0888, -0.7402]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3381,  0.5187, -0.3685, -0.6713,  0.0726,  0.2058, -0.0107,\n",
       "           0.2366, -0.4881, -0.7352]]], grad_fn=<BmmBackward>)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "util.weighted_sum(x.unsqueeze(0), w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/misc/projdata3/info_fil/finance/simon_test/allennlp_official/allennlp/allennlp/service/predictors/__init__.py:23: FutureWarning: allennlp.service.predictors.* has been depreciated. Please use allennlp.predictors.*\n",
      "  \"Please use allennlp.predictors.*\", FutureWarning)\n",
      "/misc/projdata3/info_fil/finance/simon_test/allennlp_official/allennlp/allennlp/service/predictors/predictor.py:6: FutureWarning: allennlp.service.predictors.* has been deprecated. Please use allennlp.predictors.*\n",
      "  \" Please use allennlp.predictors.*\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from my_library.models.etd_attention import MultiHeadAttentionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = MultiHeadAttentionEncoder(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2,3,10)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.tensor([[1,1,0],[0,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3324, -0.7735,  2.0834,  0.3789, -1.7387, -0.2029,  0.7632, -0.5713,\n",
       "         -0.0396, -1.0012],\n",
       "        [ 1.1416, -1.1636, -0.2683,  0.4592, -0.8949,  0.2587, -0.0739,  0.0943,\n",
       "          0.4202,  0.0145]], grad_fn=<SqueezeBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn(x,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([torch.ones(5),torch.ones(6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HAN Allennlp Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Dict, Optional, Union\n",
    "from typing import List, Dict, Iterable\n",
    "import json\n",
    "import logging\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from overrides import overrides\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import ListField, TextField, SequenceLabelField, MultiLabelField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, WordTokenizer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules import FeedForward, Seq2VecEncoder, TextFieldEmbedder, Seq2SeqEncoder\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.nn import InitializerApplicator, RegularizerApplicator, util\n",
    "from allennlp.nn.activations import Activation\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.predictors import SentenceTaggerPredictor\n",
    "\n",
    "from my_library.metrics.roc_auc_score import RocAucScore\n",
    "from my_library.metrics.hit_at_k import *\n",
    "from my_library.metrics.macro_f1 import *\n",
    "from my_library.metrics.precision_at_k import *\n",
    "from my_library.models.etd_attention import AttentionEncoder, MultiHeadAttentionEncoder\n",
    "from my_library.models.customized_allennlp.maxout import Maxout\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "global x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EtdHANAbstractReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    Reads a CSV-lines file containing abstract only from ETD records\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 merge_title_abstract: bool = False,\n",
    "                 lazy: bool = False,\n",
    "                 start_tokens: List[str] = [\"<start>\"], \n",
    "                 end_tokens: List[str] = [\"<end>\"]) -> None:\n",
    "        super().__init__(lazy)\n",
    "        self._tokenizer = tokenizer or WordTokenizer(start_tokens=start_tokens,end_tokens=end_tokens)\n",
    "        self._sentence_splitter = spacy.load('en_core_web_sm')\n",
    "        self._token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        self._merge_title_abstract = merge_title_abstract\n",
    "        \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterable[Instance]:\n",
    "        with open(cached_path(file_path), \"r\") as data_file:\n",
    "#             logger.info(\"Reading instances from lines in file at: %s\", file_path)\n",
    "            for line in data_file:\n",
    "                line = line.strip(\"\\n\")\n",
    "                if not line:\n",
    "                    continue\n",
    "                etd_json = json.loads(line)\n",
    "                labels = etd_json['lcsh']\n",
    "                if self._merge_title_abstract and 'etdTitle' in  etd_json:\n",
    "                    abstract = '%s @@@SEP@@@ %s'%(etd_json['etdTitle'],etd_json['etdAbstract'])\n",
    "                else:\n",
    "                    abstract = etd_json['etdAbstract']\n",
    "                labels = etd_json['lcsh']\n",
    "\n",
    "                yield self.text_to_instance(abstract, labels)\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, abstract_text: str, labels: Dict[str, int] = None) -> Instance:  # type: ignore\n",
    "        # pylint: disable=arguments-differ\n",
    "        sentences = [i.string.strip() for i in self._sentence_splitter(abstract_text).sents]\n",
    "        tokenized_abstract_text = [self._tokenizer.tokenize(i) for i in sentences]\n",
    "        abstract_text_field = ListField([TextField(i, self._token_indexers) for i in tokenized_abstract_text])\n",
    "        fields = {'abstract_text': abstract_text_field}\n",
    "        \n",
    "        if labels is not None:\n",
    "            fields['label'] = MultiLabelField([label for label,value in labels.items() if value == 1])\n",
    "                \n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EtdHAN(Model):\n",
    "    \"\"\"\n",
    "    vocab : ``Vocabulary``, required\n",
    "        A Vocabulary, required in order to compute sizes for input/output projections.\n",
    "    text_field_embedder : ``TextFieldEmbedder``, required\n",
    "        Used to embed the ``tokens`` ``TextField`` we get as input to the model.\n",
    "    abstract_encoder : ``Seq2VecEncoder``\n",
    "        The encoder that we will use to convert the abstract to a vector.\n",
    "    classifier_feedforward : ``FeedForward``\n",
    "    initializer : ``InitializerApplicator``, optional (default=``InitializerApplicator()``)\n",
    "        Used to initialize the model parameters.\n",
    "    regularizer : ``RegularizerApplicator``, optional (default=``None``)\n",
    "        If provided, will be used to calculate the regularization penalty during training.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab: Vocabulary,\n",
    "                 text_field_embedder: TextFieldEmbedder,\n",
    "                 word_encoder: Seq2SeqEncoder,\n",
    "                 sentence_encoder: Seq2SeqEncoder,\n",
    "                 classifier_feedforward: Union[FeedForward, Maxout],\n",
    "                 attended_text_dropout: float  = 0.0,\n",
    "                 bce_pos_weight: int = 10,\n",
    "                 use_positional_encoding: bool = False,\n",
    "                 initializer: InitializerApplicator = InitializerApplicator(),\n",
    "                 regularizer: Optional[RegularizerApplicator] = None) -> None:\n",
    "        super(EtdHAN, self).__init__(vocab, regularizer)\n",
    "\n",
    "        self.text_field_embedder = text_field_embedder\n",
    "        self.num_classes = self.vocab.get_vocab_size(\"labels\")\n",
    "        self.word_encoder = word_encoder\n",
    "        self.word_level_attention = FeedForward(word_encoder.get_output_dim(), \n",
    "                                                2, \n",
    "                                                [word_encoder.get_output_dim(), 1],\n",
    "                                                [Activation.by_name(\"tanh\")(), Activation.by_name(\"linear\")()],\n",
    "                                                [True, False])\n",
    "        self.sentence_encoder = sentence_encoder\n",
    "        self.sentence_level_attention = FeedForward(sentence_encoder.get_output_dim(), \n",
    "                                                    2, \n",
    "                                                    [sentence_encoder.get_output_dim(), 1],\n",
    "                                                    [Activation.by_name(\"tanh\")(), Activation.by_name(\"linear\")()],\n",
    "                                                    [True, False])\n",
    "        self.classifier_feedforward = classifier_feedforward\n",
    "        self.use_positional_encoding = use_positional_encoding\n",
    "\n",
    "        self._dropout = torch.nn.Dropout(attended_text_dropout)\n",
    "        \n",
    "        if text_field_embedder.get_output_dim() != word_encoder.get_input_dim():\n",
    "            raise ConfigurationError(\"The output dimension of the text_field_embedder must match the \"\n",
    "                                     \"input dimension of the word_encoder. Found {} and {}, \"\n",
    "                                     \"respectively.\".format(text_field_embedder.get_output_dim(),\n",
    "                                                            word_encoder.get_input_dim()))\n",
    "\n",
    "        self.metrics = {\n",
    "#             \"roc_auc_score\": RocAucScore()            \n",
    "            \"hit_5\": HitAtK(5),\n",
    "            \"hit_10\": HitAtK(10),\n",
    "            \"precision_5\": PrecisionAtK(5),\n",
    "            \"precision_10\": PrecisionAtK(10)\n",
    "#             \"hit_100\": HitAtK(100),\n",
    "#             \"macro_measure\": MacroF1Measure(top_k=5,num_label=self.num_classes)\n",
    "        }\n",
    "        \n",
    "        self.loss = torch.nn.BCEWithLogitsLoss(pos_weight = torch.ones(self.num_classes)*bce_pos_weight)\n",
    "\n",
    "        initializer(self)\n",
    "\n",
    "    @overrides\n",
    "    def forward(self,  # type: ignore\n",
    "                abstract_text: Dict[str, torch.LongTensor],\n",
    "                label: torch.LongTensor = None) -> Dict[str, torch.Tensor]:\n",
    "        # pylint: disable=arguments-differ\n",
    "        embedded_abstract_text = self.text_field_embedder(abstract_text, num_wrapping_dims=1)\n",
    "        abstract_text_mask = util.get_text_field_mask(abstract_text, num_wrapping_dims=1)\n",
    "        \n",
    "        print(embedded_abstract_text.size())\n",
    "        num_instance, num_sentence, num_word, _ = embedded_abstract_text.size()\n",
    "        embedded_abstract_text = embedded_abstract_text.view(num_instance*num_sentence, num_word, -1)\n",
    "        abstract_text_mask = abstract_text_mask.view(num_instance*num_sentence, -1)\n",
    "\n",
    "        if self.use_positional_encoding:\n",
    "            embedded_abstract_text = util.add_positional_features(embedded_abstract_text)\n",
    "        encoded_abstract_text = self.word_encoder(embedded_abstract_text, abstract_text_mask)\n",
    "        \n",
    "        word_attentive_weights = self.word_level_attention(encoded_abstract_text)\n",
    "        word_attentive_weights = util.masked_softmax(word_attentive_weights.transpose(1,2), \n",
    "                                                     abstract_text_mask, dim=2).transpose(1,2)\n",
    "        attended_sentences = util.weighted_sum(encoded_abstract_text,word_attentive_weights.squeeze())\n",
    "        \n",
    "        attended_sentences = attended_sentences.view(num_instance, num_sentence, -1)\n",
    "        abstract_text_mask = abstract_text_mask.view(num_instance, num_sentence, -1).sum(2).ge(1).long()\n",
    "        \n",
    "        if self.use_positional_encoding:\n",
    "            attended_sentences = util.add_positional_features(attended_sentences)\n",
    "        attended_sentences = self.sentence_encoder(attended_sentences, abstract_text_mask)\n",
    "        \n",
    "        sentence_attentive_weights = self.sentence_level_attention(attended_sentences)\n",
    "        sentence_attentive_weights = util.masked_softmax(sentence_attentive_weights.transpose(1,2), \n",
    "                                                         abstract_text_mask, dim=2).transpose(1,2)\n",
    "        attended_abstract_text = util.weighted_sum(attended_sentences,sentence_attentive_weights.squeeze())\n",
    "        attended_abstract_text = self._dropout(attended_abstract_text)\n",
    "        \n",
    "        outputs = self.classifier_feedforward(attended_abstract_text)\n",
    "        logits = torch.sigmoid(outputs)\n",
    "        logits = logits.unsqueeze(0) if len(logits.size()) < 2 else logits\n",
    "        output_dict = {'logits': logits}\n",
    "\n",
    "        if label is not None:\n",
    "            outputs = outputs.unsqueeze(0) if len(outputs.size()) < 2 else outputs\n",
    "            loss = self.loss(outputs, label.squeeze(-1))\n",
    "            for metric in self.metrics.values():\n",
    "                metric(logits, label.squeeze(-1))\n",
    "            output_dict[\"loss\"] = loss\n",
    "            \n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Does a simple argmax over the class probabilities, converts indices to string labels, and\n",
    "        adds a ``\"label\"`` key to the dictionary with the result.\n",
    "        \"\"\"\n",
    "        # class_probabilities = output_dict['logits']\n",
    "        # output_dict['class_probabilities'] = class_probabilities\n",
    "\n",
    "        # predictions = class_probabilities.cpu().data.numpy()\n",
    "        # labels = [list(self.vocab.get_index_to_token_vocabulary(namespace=\"labels\").values()) for i in range(len(output_dict['logits']))]\n",
    "        # output_dict['label'] = labels\n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "#         metric_dict = {metric_name: metric.get_metric(reset) for metric_name, metric in self.metrics.items()}\n",
    "        metric_dict = {}\n",
    "        metric_dict['hit_5'] = self.metrics['hit_5'].get_metric(reset)\n",
    "        metric_dict['hit_10'] = self.metrics['hit_10'].get_metric(reset)\n",
    "#         metric_dict['hit_100'] = self.metrics['hit_100'].get_metric(reset)\n",
    "        metric_dict['precision_5'] = self.metrics['precision_5'].get_metric(reset)\n",
    "        metric_dict['precision_10'] = self.metrics['precision_10'].get_metric(reset)\n",
    "#         macro_measure = self.metrics['macro_measure'].get_metric(reset)\n",
    "#         metric_dict['mac_prec'] = macro_measure[0]\n",
    "#         metric_dict['mac_rec'] = macro_measure[1]\n",
    "#         metric_dict['mac_f1'] = macro_measure[2]\n",
    "        return metric_dict\n",
    "\n",
    "    @classmethod\n",
    "    def from_params(cls, vocab: Vocabulary, params: Params) -> 'EtdHAN':\n",
    "        embedder_params = params.pop(\"text_field_embedder\")\n",
    "        text_field_embedder = TextFieldEmbedder.from_params(vocab=vocab, params=embedder_params)\n",
    "        word_encoder = Seq2SeqEncoder.from_params(params.pop(\"word_encoder\"))\n",
    "        sentence_encoder = Seq2SeqEncoder.from_params(params.pop(\"sentence_encoder\"))\n",
    "        classifier_feedforward = params.pop(\"classifier_feedforward\")\n",
    "        if classifier_feedforward.pop('type') == 'feedforward':\n",
    "            classifier_feedforward = FeedForward.from_params(classifier_feedforward)\n",
    "        else:\n",
    "            classifier_feedforward = Maxout.from_params(classifier_feedforward)\n",
    "        use_positional_encoding = params.pop(\"use_positional_encoding\", False)\n",
    "        bce_pos_weight = params.pop_int(\"bce_pos_weight\", 10)\n",
    "        attended_text_dropout = params.pop_float(\"attended_text_dropout\", 0.0)\n",
    "\n",
    "        initializer = InitializerApplicator.from_params(params.pop('initializer', []))\n",
    "        regularizer = RegularizerApplicator.from_params(params.pop('regularizer', []))\n",
    "\n",
    "        return cls(vocab=vocab,\n",
    "                   text_field_embedder=text_field_embedder,\n",
    "                   word_encoder=word_encoder,\n",
    "                   sentence_encoder=sentence_encoder,\n",
    "                   classifier_feedforward=classifier_feedforward,\n",
    "                   attended_text_dropout=attended_text_dropout,\n",
    "                   bce_pos_weight=bce_pos_weight,\n",
    "                   use_positional_encoding=use_positional_encoding,\n",
    "                   initializer=initializer,\n",
    "                   regularizer=regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = EtdHANAbstractReader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  6.96it/s]\u001b[A\n",
      "3it [00:00, 11.16it/s]\u001b[A\n",
      "6it [00:00, 14.48it/s]\u001b[A\n",
      "9it [00:00, 16.50it/s]\u001b[A\n",
      "11it [00:00, 16.58it/s]\u001b[A\n",
      "13it [00:00, 14.50it/s]\u001b[A\n",
      "15it [00:00, 15.02it/s]\u001b[A\n",
      "18it [00:01, 16.13it/s]\u001b[A\n",
      "21it [00:01, 16.31it/s]\u001b[A\n",
      "23it [00:01, 16.24it/s]\u001b[A\n",
      "25it [00:01, 16.05it/s]\u001b[A\n",
      "27it [00:01, 16.19it/s]\u001b[A\n",
      "29it [00:01, 15.86it/s]\u001b[A\n",
      "31it [00:01, 15.95it/s]\u001b[A\n",
      "34it [00:02, 16.44it/s]\u001b[A\n",
      "36it [00:02, 16.49it/s]\u001b[A\n",
      "38it [00:02, 16.62it/s]\u001b[A\n",
      "41it [00:02, 16.47it/s]\u001b[A\n",
      "43it [00:02, 16.29it/s]\u001b[A\n",
      "45it [00:02, 15.44it/s]\u001b[A\n",
      "47it [00:03, 15.56it/s]\u001b[A\n",
      "50it [00:03, 15.95it/s]\u001b[A\n",
      "53it [00:03, 16.15it/s]\u001b[A\n",
      "56it [00:03, 16.39it/s]\u001b[A\n",
      "60it [00:03, 16.80it/s]\u001b[A\n",
      "63it [00:03, 16.74it/s]\u001b[A\n",
      "65it [00:03, 16.67it/s]\u001b[A\n",
      "67it [00:04, 16.58it/s]\u001b[A\n",
      "69it [00:04, 16.65it/s]\u001b[A\n",
      "71it [00:04, 16.70it/s]\u001b[A\n",
      "73it [00:04, 16.77it/s]\u001b[A\n",
      "76it [00:04, 16.89it/s]\u001b[A\n",
      "79it [00:04, 16.83it/s]\u001b[A\n",
      "82it [00:04, 16.84it/s]\u001b[A\n",
      "84it [00:05, 16.79it/s]\u001b[A\n",
      "86it [00:05, 16.75it/s]\u001b[A\n",
      "88it [00:05, 16.78it/s]\u001b[A\n",
      "91it [00:05, 16.80it/s]\u001b[A\n",
      "94it [00:05, 16.96it/s]\u001b[A\n",
      "\u001b[A\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "2it [00:00, 14.45it/s]\u001b[A\n",
      "4it [00:00, 16.51it/s]\u001b[A\n",
      "7it [00:00, 20.25it/s]\u001b[A\n",
      "10it [00:00, 19.58it/s]\u001b[A\n",
      "12it [00:00, 18.14it/s]\u001b[A\n",
      "14it [00:00, 16.75it/s]\u001b[A\n",
      "17it [00:00, 17.86it/s]\u001b[A\n",
      "20it [00:01, 18.18it/s]\u001b[A\n",
      "22it [00:01, 17.05it/s]\u001b[A\n",
      "25it [00:01, 16.95it/s]\u001b[A\n",
      "27it [00:01, 17.10it/s]\u001b[A\n",
      "29it [00:01, 16.65it/s]\u001b[A\n",
      "31it [00:01, 16.64it/s]\u001b[A\n",
      "34it [00:01, 17.17it/s]\u001b[A\n",
      "36it [00:02, 17.25it/s]\u001b[A\n",
      "39it [00:02, 17.60it/s]\u001b[A\n",
      "42it [00:02, 17.15it/s]\u001b[A\n",
      "44it [00:02, 16.90it/s]\u001b[A\n",
      "47it [00:02, 17.02it/s]\u001b[A\n",
      "50it [00:02, 17.43it/s]\u001b[A\n",
      "53it [00:03, 17.62it/s]\u001b[A\n",
      "56it [00:03, 17.87it/s]\u001b[A\n",
      "60it [00:03, 18.28it/s]\u001b[A\n",
      "63it [00:03, 18.13it/s]\u001b[A\n",
      "66it [00:03, 18.06it/s]\u001b[A\n",
      "68it [00:03, 18.09it/s]\u001b[A\n",
      "70it [00:03, 18.12it/s]\u001b[A\n",
      "72it [00:03, 18.15it/s]\u001b[A\n",
      "75it [00:04, 18.38it/s]\u001b[A\n",
      "78it [00:04, 18.39it/s]\u001b[A\n",
      "81it [00:04, 18.30it/s]\u001b[A\n",
      "83it [00:04, 17.92it/s]\u001b[A\n",
      "86it [00:04, 18.04it/s]\u001b[A\n",
      "88it [00:04, 18.03it/s]\u001b[A\n",
      "91it [00:05, 18.04it/s]\u001b[A\n",
      "94it [00:05, 18.19it/s]\u001b[A\n",
      "\u001b[A\n",
      "  0%|          | 0/188 [00:00<?, ?it/s]\u001b[A\n",
      " 63%|██████▎   | 119/188 [00:00<00:00, 1141.57it/s]\u001b[A\n",
      "100%|██████████| 188/188 [00:00<00:00, 960.98it/s] \u001b[A"
     ]
    }
   ],
   "source": [
    "train_dataset = reader.read(cached_path(\n",
    "    \"/misc/projdata3/info_fil/finance/simon_test/ETD_cataloguing/allennlp-test/data/etd_debug.json\"))\n",
    "validation_dataset = reader.read(cached_path(\n",
    "    \"/misc/projdata3/info_fil/finance/simon_test/ETD_cataloguing/allennlp-test/data/etd_debug.json\"))\n",
    "vocab = Vocabulary.from_instances(train_dataset + validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6\n",
    "token_embedding = Embedding(num_embeddings=vocab.get_vocab_size('tokens'),\n",
    "                            embedding_dim=EMBEDDING_DIM)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": token_embedding})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(EMBEDDING_DIM, HIDDEN_DIM, bidirectional=True, batch_first=True))\n",
    "sentence_lstm = PytorchSeq2SeqWrapper(torch.nn.LSTM(12, HIDDEN_DIM, bidirectional=True, batch_first=True))\n",
    "ff = FeedForward(12,1,241,Activation.by_name(\"linear\")())\n",
    "model = EtdHAN(vocab,\n",
    "               text_field_embedder=word_embeddings, \n",
    "               word_encoder=word_lstm,\n",
    "               sentence_encoder=sentence_lstm,\n",
    "#                attention_encoder=attention_encoder,\n",
    "               classifier_feedforward=ff)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "# iterator = BucketIterator(batch_size=16, sorting_keys=[(\"abstract_text\", \"list_num_tokens\"),(\"abstract_text\", \"num_fields\")])\n",
    "# iterator = BucketIterator(batch_size=16, sorting_keys=[(\"abstract_text\", \"num_fields\")])\n",
    "iterator = BucketIterator(batch_size=1, sorting_keys=[(\"abstract_text\", \"list_num_tokens\")])\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  train_dataset=train_dataset,\n",
    "                  validation_dataset=validation_dataset,\n",
    "                  patience=10,\n",
    "                  num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0000, hit_10: 0.0000, precision_5: 0.0000, precision_10: 0.0000, loss: 0.7699 ||:   1%|          | 1/94 [00:00<00:14,  6.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 64, 6])\n",
      "torch.Size([1, 27, 59, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0000, hit_10: 0.0000, precision_5: 0.0000, precision_10: 0.0000, loss: 0.7433 ||:   3%|▎         | 3/94 [00:00<00:09,  9.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0000, hit_10: 0.0400, precision_5: 0.0000, precision_10: 0.0200, loss: 0.7604 ||:   5%|▌         | 5/94 [00:00<00:07, 12.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 13, 56, 6])\n",
      "torch.Size([1, 9, 48, 6])\n",
      "torch.Size([1, 14, 51, 6])\n",
      "torch.Size([1, 3, 18, 6])\n",
      "torch.Size([1, 17, 105, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0357, hit_10: 0.0643, precision_5: 0.0286, precision_10: 0.0286, loss: 0.7613 ||:   7%|▋         | 7/94 [00:00<00:06, 12.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0278, hit_10: 0.0500, precision_5: 0.0222, precision_10: 0.0222, loss: 0.7602 ||:  10%|▉         | 9/94 [00:00<00:06, 13.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 29, 42, 6])\n",
      "torch.Size([1, 16, 56, 6])\n",
      "torch.Size([1, 10, 48, 6])\n",
      "torch.Size([1, 27, 51, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0227, hit_10: 0.0409, precision_5: 0.0182, precision_10: 0.0182, loss: 0.7652 ||:  12%|█▏        | 11/94 [00:00<00:06, 13.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0192, hit_10: 0.0346, precision_5: 0.0154, precision_10: 0.0154, loss: 0.7689 ||:  14%|█▍        | 13/94 [00:00<00:05, 14.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 29, 50, 6])\n",
      "torch.Size([1, 10, 37, 6])\n",
      "torch.Size([1, 7, 50, 6])\n",
      "torch.Size([1, 19, 60, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0167, hit_10: 0.0433, precision_5: 0.0133, precision_10: 0.0200, loss: 0.7709 ||:  16%|█▌        | 15/94 [00:01<00:05, 14.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0147, hit_10: 0.0676, precision_5: 0.0118, precision_10: 0.0235, loss: 0.7721 ||:  18%|█▊        | 17/94 [00:01<00:05, 15.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 30, 44, 6])\n",
      "torch.Size([1, 11, 36, 6])\n",
      "torch.Size([1, 29, 66, 6])\n",
      "torch.Size([1, 16, 35, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0132, hit_10: 0.0605, precision_5: 0.0105, precision_10: 0.0211, loss: 0.7679 ||:  20%|██        | 19/94 [00:01<00:04, 15.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0119, hit_10: 0.0548, precision_5: 0.0095, precision_10: 0.0190, loss: 0.7671 ||:  22%|██▏       | 21/94 [00:01<00:04, 15.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 23, 45, 6])\n",
      "torch.Size([1, 26, 59, 6])\n",
      "torch.Size([1, 22, 55, 6])\n",
      "torch.Size([1, 16, 70, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0109, hit_10: 0.0500, precision_5: 0.0087, precision_10: 0.0174, loss: 0.7677 ||:  24%|██▍       | 23/94 [00:01<00:04, 15.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0100, hit_10: 0.0460, precision_5: 0.0080, precision_10: 0.0160, loss: 0.7688 ||:  27%|██▋       | 25/94 [00:01<00:04, 15.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 15, 66, 6])\n",
      "torch.Size([1, 10, 46, 6])\n",
      "torch.Size([1, 23, 36, 6])\n",
      "torch.Size([1, 16, 53, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0093, hit_10: 0.0426, precision_5: 0.0074, precision_10: 0.0148, loss: 0.7669 ||:  29%|██▊       | 27/94 [00:01<00:04, 15.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0086, hit_10: 0.0397, precision_5: 0.0069, precision_10: 0.0138, loss: 0.7674 ||:  31%|███       | 29/94 [00:01<00:04, 15.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 23, 69, 6])\n",
      "torch.Size([1, 22, 54, 6])\n",
      "torch.Size([1, 45, 61, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0081, hit_10: 0.0371, precision_5: 0.0065, precision_10: 0.0129, loss: 0.7663 ||:  33%|███▎      | 31/94 [00:01<00:04, 15.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0076, hit_10: 0.0348, precision_5: 0.0061, precision_10: 0.0121, loss: 0.7666 ||:  35%|███▌      | 33/94 [00:02<00:03, 15.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 18, 64, 6])\n",
      "torch.Size([1, 17, 50, 6])\n",
      "torch.Size([1, 33, 49, 6])\n",
      "torch.Size([1, 26, 50, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0167, hit_10: 0.0424, precision_5: 0.0114, precision_10: 0.0143, loss: 0.7674 ||:  37%|███▋      | 35/94 [00:02<00:03, 15.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 64, 6])\n",
      "torch.Size([1, 35, 75, 6])\n",
      "torch.Size([1, 15, 66, 6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0158, hit_10: 0.0401, precision_5: 0.0108, precision_10: 0.0135, loss: 0.7692 ||:  39%|███▉      | 37/94 [00:02<00:03, 15.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "hit_5: 0.0150, hit_10: 0.0380, precision_5: 0.0103, precision_10: 0.0128, loss: 0.7682 ||:  41%|████▏     | 39/94 [00:02<00:03, 15.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 68, 6])\n",
      "torch.Size([1, 12, 40, 6])\n",
      "torch.Size([1, 9, 34, 6])\n",
      "torch.Size([1, 23, 62, 6])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-376-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/misc/projdata3/info_fil/finance/simon_test/allennlp_official/allennlp/allennlp/training/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0;31m# count those batches for which we actually have a loss.  If this variable ever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                 \u001b[0;31m# gets used for something else, we might need to change things around a bit.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m                 \u001b[0mbatches_this_epoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0mval_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/projdata3/info_fil/finance/simon_test/allennlp_official/allennlp/allennlp/training/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mbatches_this_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_num_total\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_num_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_histogram_interval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projdata3/info_fil/finance/simon_test/anaconda2/envs/torch-gpu/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projdata3/info_fil/finance/simon_test/anaconda2/envs/torch-gpu/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 19, 75, 6]), torch.Size([16, 19, 75]))"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(),y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 19])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(2).ge(1).long().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168],\n",
       "        [ 0.0145, -0.0124, -0.0054,  0.0132, -0.0264,  0.0168]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object EtdAbstractReader._read at 0x7f9370bb8eb8>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader._read(cached_path(\n",
    "    \"/misc/projdata3/info_fil/finance/simon_test/ETD_cataloguing/allennlp-test/data/etd_debug.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object DataIterator.__call__ at 0x7f93719f1f10>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterator(reader._read(cached_path(\"/misc/projdata3/info_fil/finance/simon_test/ETD_cataloguing/allennlp-test/data/etd_debug.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i am an apple', 'you are a boy']"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'@@@sent@@@'.join(['i am an apple','you are a boy']).split(\"@@@sent@@@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3,10)\n",
    "mask = torch.randn(3,10).ge(0.5).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 1, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 1, 1, 0, 0, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 1, 1, 0, 0, 1, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-326-d6201e6af21c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.FloatTensor but found type torch.LongTensor for argument #2 'other'"
     ]
    }
   ],
   "source": [
    "x*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b= x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 10\n",
    "hidden_dim = 5\n",
    "num_hops = 3\n",
    "\n",
    "x = torch.randn(5,6,input_dim)\n",
    "mask = torch.randn(5,6).ge(0.3).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 1],\n",
       "        [0, 1, 0, 1, 1, 1],\n",
       "        [0, 1, 1, 1, 0, 1],\n",
       "        [1, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_attention = torch.nn.Sequential(torch.nn.Linear(input_dim, hidden_dim, False), \n",
    "                                     torch.nn.Tanh(),\n",
    "                                     torch.nn.Linear(hidden_dim, num_hops, False)\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = self_attention(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = util.masked_softmax(A.transpose(1,2), mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 6])"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1309,  0.1582, -0.2105,  1.2122,  0.8495,  0.7268,  0.3333,  1.0941,\n",
       "          1.3880, -0.2298],\n",
       "        [-0.0723,  0.1661, -0.3527,  1.2330,  1.0729,  0.7947,  0.3510,  1.0121,\n",
       "          1.5219, -0.1599],\n",
       "        [ 0.0643,  0.1608, -0.2571,  1.2190,  0.9227,  0.7490,  0.3391,  1.0672,\n",
       "          1.4319, -0.2069]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(A,x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1309,  0.1582, -0.2105,  1.2122,  0.8495,  0.7268,  0.3333,  1.0941,\n",
       "         1.3880, -0.2298, -0.0723,  0.1661, -0.3527,  1.2330,  1.0729,  0.7947,\n",
       "         0.3510,  1.0121,  1.5219, -0.1599,  0.0643,  0.1608, -0.2571,  1.2190,\n",
       "         0.9227,  0.7490,  0.3391,  1.0672,  1.4319, -0.2069],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(A,x).view(-1, num_hops * input_dim)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3969, grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(torch.bmm(A, A.transpose(1,2).contiguous()) - torch.eye(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.4291, grad_fn=<NormBackward0>)"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.bmm(A, A.transpose(1,2).contiguous())[0] - torch.eye(3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.5388, grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(torch.norm(i).pow(2) for i in torch.bmm(A, A.transpose(1,2).contiguous()) - torch.eye(3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.5388, grad_fn=<ThAddBackward>)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = A.size(1)\n",
    "sum(torch.norm(i).pow(2) for i in torch.bmm(A, A.transpose(1,2).contiguous()) - torch.eye(dim, dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9875,  0.1247,  0.3889,  1.1244, -0.0923,  0.4405,  0.2590,\n",
       "           1.4398,  0.8235, -0.5243],\n",
       "         [ 0.2079, -0.1711, -0.8862,  0.0658,  0.0013, -1.0030,  1.6640,\n",
       "          -0.3270, -0.2209, -0.0746],\n",
       "         [ 0.7866,  1.2049,  0.9012, -2.4279, -1.3341, -0.3021, -1.7082,\n",
       "           0.1294, -0.5443, -1.2326],\n",
       "         [ 2.2070, -1.8742, -0.2466,  0.7570,  2.2890,  0.4324, -0.6218,\n",
       "           3.2024, -1.4096, -1.1646],\n",
       "         [ 0.0746, -0.3600,  0.6546, -0.8156, -1.2023, -0.3194, -1.8417,\n",
       "          -0.4588, -1.5632,  1.3000],\n",
       "         [-0.9024,  0.1985, -0.9335,  1.3181,  1.9855,  1.0721,  0.4230,\n",
       "           0.6771,  2.0690,  0.1254]],\n",
       "\n",
       "        [[ 1.1420,  0.0429, -0.0520,  0.3217, -1.1615,  0.5248,  0.9057,\n",
       "          -0.6426,  0.0792, -0.0363],\n",
       "         [ 0.7093,  0.7981, -1.4593,  0.8239, -0.4603,  0.3756, -0.4871,\n",
       "          -0.3300,  0.3276, -0.6304],\n",
       "         [ 0.3538, -0.4720,  0.0376,  0.9079, -0.1565, -0.4418,  1.0397,\n",
       "           0.7421,  0.1620, -0.6624],\n",
       "         [-0.5795, -1.1981,  0.4214,  0.5771,  1.2567, -0.2425,  0.3541,\n",
       "           2.3524, -0.7499,  1.0111],\n",
       "         [-1.0474, -0.6537,  1.3714, -0.3723, -1.6969, -1.4227,  0.7333,\n",
       "           1.0375, -0.6988,  1.6163],\n",
       "         [-0.3118,  2.6294,  0.7671, -0.0242,  0.1061,  1.4285,  0.5863,\n",
       "           0.3174, -0.3521,  0.1572]],\n",
       "\n",
       "        [[ 0.1483,  1.0584, -0.7543, -0.7732,  0.9965, -0.1248,  0.1953,\n",
       "          -0.9116, -1.0540, -0.1983],\n",
       "         [-0.1045, -2.3999,  0.5125,  0.3416, -0.0171, -1.7742,  1.2329,\n",
       "           1.0299,  0.5109,  1.1247],\n",
       "         [-0.8419,  0.3547,  0.7046,  0.7838,  0.4630,  0.0549, -0.3268,\n",
       "          -0.8731,  1.6846, -1.7335],\n",
       "         [-0.4751,  0.1854,  0.4593, -0.5444, -0.8398,  0.0372,  1.2525,\n",
       "           0.6241,  0.4501,  0.8506],\n",
       "         [-0.1895, -0.8821,  1.2685,  1.3412, -0.7646, -0.6437, -0.8917,\n",
       "           0.4508, -0.8149, -0.6712],\n",
       "         [ 1.0904,  0.4247, -0.0379,  0.1114,  1.1373,  0.4680,  1.8723,\n",
       "          -1.1353,  0.7735, -0.7202]],\n",
       "\n",
       "        [[-0.3221, -0.3254, -0.3241,  0.1717, -0.3342,  0.5161, -1.2128,\n",
       "           0.4106, -0.3710, -0.8105],\n",
       "         [-1.5235, -0.2070,  0.9710,  1.4437, -0.9287, -1.7664, -0.5119,\n",
       "          -0.0450,  1.6981,  0.9032],\n",
       "         [ 0.6873,  0.4993,  0.4582,  2.0186, -0.8050,  1.9262, -1.0774,\n",
       "           2.0342,  0.5411, -1.2128],\n",
       "         [-1.6851,  0.4703, -0.9999,  0.9577,  1.1249, -0.7172, -0.4726,\n",
       "          -0.3663,  0.5728,  0.0486],\n",
       "         [-1.1764,  0.6948, -1.5105,  0.3714, -0.6960,  1.0125, -0.5542,\n",
       "           1.1021, -1.4091, -0.3385],\n",
       "         [ 1.1077, -0.6805, -0.4658,  1.7675, -0.0726, -0.3270, -0.9852,\n",
       "           0.9318,  0.8427, -0.0329]],\n",
       "\n",
       "        [[ 0.4042, -0.5211, -2.4029, -0.3786,  1.3154,  0.7413, -0.1207,\n",
       "          -0.7483,  0.3317,  1.4615],\n",
       "         [ 0.1944,  0.7006,  0.6686,  1.0795, -0.9494,  0.7367, -0.6334,\n",
       "          -0.7759,  1.4891, -0.4506],\n",
       "         [ 0.2820, -0.0175, -0.6911,  2.0582, -0.8261, -0.7769,  0.6690,\n",
       "           0.3136,  1.0245,  0.6884],\n",
       "         [-1.0949,  1.7464,  0.3718,  0.6288,  0.2987, -2.2342, -0.8071,\n",
       "          -0.7210,  0.3341, -0.9805],\n",
       "         [-0.8011,  0.5091, -0.9034,  0.0209, -1.7409,  0.0232, -0.0474,\n",
       "           0.7595, -0.7518, -1.3678],\n",
       "         [ 0.3845, -2.1778, -0.0887, -1.1345,  0.7822,  0.2135, -0.3746,\n",
       "          -1.7690,  1.0276,  2.2445]]])"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2070,  1.2049,  0.9012,  1.3181,  2.2890,  1.0721,  1.6640,  3.2024,\n",
       "          2.0690,  1.3000],\n",
       "        [ 1.1420,  2.6294,  1.3714,  0.9079,  1.2567,  1.4285,  1.0397,  2.3524,\n",
       "          0.3276,  1.6163],\n",
       "        [ 1.0904,  1.0584,  1.2685,  1.3412,  1.1373,  0.4680,  1.8723,  1.0299,\n",
       "          1.6846,  1.1247],\n",
       "        [ 1.1077,  0.6948,  0.9710,  2.0186,  1.1249,  1.9262, -0.4726,  2.0342,\n",
       "          1.6981,  0.9032],\n",
       "        [ 0.4042,  1.7464,  0.6686,  2.0582,  1.3154,  0.7413,  0.6690,  0.7595,\n",
       "          1.4891,  2.2445]])"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 10])"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 20])"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([x,y],dim=2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 6, 10, 2])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([x,y],dim=3).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
