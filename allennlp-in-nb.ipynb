{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, List, Dict\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField, SequenceLabelField\n",
    "from allennlp.data.dataset_readers import DatasetReader\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.tokenizers import Token\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.models import Model\n",
    "from allennlp.nn import Activation\n",
    "from allennlp.modules import FeedForward\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.modules.token_embedders import Embedding\n",
    "from allennlp.modules.token_embedders.embedding import _read_pretrained_embeddings_file\n",
    "from allennlp.modules.seq2seq_encoders import Seq2SeqEncoder, PytorchSeq2SeqWrapper\n",
    "from allennlp.nn.util import get_text_field_mask, sequence_cross_entropy_with_logits\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.data.iterators import BucketIterator\n",
    "from allennlp.training.trainer import Trainer\n",
    "from allennlp.predictors import SentenceTaggerPredictor\n",
    "\n",
    "from my_library.dataset_readers import EtdTitleAbstractReader\n",
    "from my_library.models.etd_bcn import EtdBCN\n",
    "from my_library.models.etd_biattention import BiAttentionEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Iterable\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from overrides import overrides\n",
    "\n",
    "import tqdm\n",
    "\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.common.file_utils import cached_path\n",
    "#from allennlp.data.dataset import Dataset\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.data.fields import LabelField, TextField, MetadataField, ListField\n",
    "from allennlp.data.fields.multilabel_field import MultiLabelField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.tokenizers import Token, Tokenizer, WordTokenizer\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "\n",
    "# from multi_toxic_label.fields.multi_label_field import MultiLabelField\n",
    "\n",
    "class EtdAbstractReader(DatasetReader):\n",
    "    \"\"\"\n",
    "    Reads a CSV-lines file containing abstract only from ETD records\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 tokenizer: Tokenizer = None,\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None,\n",
    "                 lazy: bool = False,\n",
    "                 start_tokens: List[str] = [\"<start>\"], \n",
    "                 end_tokens: List[str] = [\"<end>\"]) -> None:\n",
    "        super().__init__(lazy)\n",
    "        self._tokenizer = tokenizer or WordTokenizer(start_tokens=start_tokens,end_tokens=end_tokens)\n",
    "        self._token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        \n",
    "    @overrides\n",
    "    def _read(self, file_path: str) -> Iterable[Instance]:\n",
    "        with open(cached_path(file_path), \"r\") as data_file:\n",
    "            logger.info(\"Reading instances from lines in file at: %s\", file_path)\n",
    "            for line in data_file:\n",
    "                line = line.strip(\"\\n\")\n",
    "                if not line:\n",
    "                    continue\n",
    "                etd_json = json.loads(line)\n",
    "                abstract = etd_json['etdAbstract']\n",
    "                labels = etd_json['lcsh']\n",
    "\n",
    "                yield self.text_to_instance(abstract, labels)\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self, abstract_text: str, labels: Dict[str, int] = None) -> Instance:  # type: ignore\n",
    "        # pylint: disable=arguments-differ\n",
    "        tokenized_abstract_text = self._tokenizer.tokenize(abstract_text)\n",
    "        abstract_text_field = TextField(tokenized_abstract_text, self._token_indexers)\n",
    "        fields = {'tokens': abstract_text_field}\n",
    "        \n",
    "        if labels is not None:\n",
    "            fields['label'] = MultiLabelField([label for label,value in labels.items() if value == 1])\n",
    "                \n",
    "        return Instance(fields)\n",
    "\n",
    "#     @classmethod\n",
    "#     def from_params(cls, params: Params) -> 'EtdDatasetReader':\n",
    "#         tokenizer = Tokenizer.from_params(params.pop('tokenizer', {}))\n",
    "#         token_indexers = TokenIndexer.dict_from_params(params.pop('token_indexers', {}))\n",
    "#         lazy = params.pop('lazy', False)\n",
    "#         params.assert_empty(cls.__name__)\n",
    "#         return cls(tokenizer=tokenizer, token_indexers=token_indexers, lazy=lazy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Union\n",
    "\n",
    "import numpy\n",
    "from overrides import overrides\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from allennlp.common import Params\n",
    "from allennlp.common.checks import check_dimensions_match, ConfigurationError\n",
    "from allennlp.data import Vocabulary\n",
    "from allennlp.modules import Elmo, FeedForward, Maxout, Seq2SeqEncoder, TextFieldEmbedder\n",
    "from allennlp.models.model import Model\n",
    "from allennlp.nn import InitializerApplicator, RegularizerApplicator\n",
    "from allennlp.nn import util\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from my_library.metrics.hit_at_k import *\n",
    "\n",
    "\n",
    "class BiattentiveClassificationNetwork(Model):\n",
    "    def __init__(self,\n",
    "                 vocab: Vocabulary,\n",
    "                 text_field_embedder: TextFieldEmbedder,\n",
    "                 embedding_dropout: float,\n",
    "                 pre_encode_feedforward: FeedForward,\n",
    "                 encoder: Seq2SeqEncoder,\n",
    "                 integrator: Seq2SeqEncoder,\n",
    "                 integrator_dropout: float,\n",
    "                 output_layer: Union[FeedForward, Maxout],\n",
    "                 elmo: Elmo,\n",
    "                 use_input_elmo: bool = False,\n",
    "                 use_integrator_output_elmo: bool = False,\n",
    "                 initializer: InitializerApplicator = InitializerApplicator(),\n",
    "                 regularizer: Optional[RegularizerApplicator] = None) -> None:\n",
    "        super(BiattentiveClassificationNetwork, self).__init__(vocab, regularizer)\n",
    "\n",
    "        self._text_field_embedder = text_field_embedder\n",
    "        if \"elmo\" in self._text_field_embedder._token_embedders.keys():  # pylint: disable=protected-access\n",
    "            raise ConfigurationError(\"To use ELMo in the BiattentiveClassificationNetwork input, \"\n",
    "                                     \"remove elmo from the text_field_embedder and pass an \"\n",
    "                                     \"Elmo object to the BiattentiveClassificationNetwork and set the \"\n",
    "                                     \"'use_input_elmo' and 'use_integrator_output_elmo' flags accordingly.\")\n",
    "        self._embedding_dropout = nn.Dropout(embedding_dropout)\n",
    "        self._num_classes = self.vocab.get_vocab_size(\"labels\")\n",
    "\n",
    "        self._pre_encode_feedforward = pre_encode_feedforward\n",
    "        self._encoder = encoder\n",
    "        self._integrator = integrator\n",
    "        self._integrator_dropout = nn.Dropout(integrator_dropout)\n",
    "\n",
    "        self._elmo = elmo\n",
    "        self._use_input_elmo = use_input_elmo\n",
    "        self._use_integrator_output_elmo = use_integrator_output_elmo\n",
    "        self._num_elmo_layers = int(self._use_input_elmo) + int(self._use_integrator_output_elmo)\n",
    "        # Check that, if elmo is None, none of the elmo flags are set.\n",
    "        if self._elmo is None and self._num_elmo_layers != 0:\n",
    "            raise ConfigurationError(\"One of 'use_input_elmo' or 'use_integrator_output_elmo' is True, \"\n",
    "                                     \"but no Elmo object was provided upon construction. Pass in an Elmo \"\n",
    "                                     \"object to use Elmo.\")\n",
    "\n",
    "        if self._elmo is not None:\n",
    "            # Check that, if elmo is not None, we use it somewhere.\n",
    "            if self._num_elmo_layers == 0:\n",
    "                raise ConfigurationError(\"Elmo object provided upon construction, but both 'use_input_elmo' \"\n",
    "                                         \"and 'use_integrator_output_elmo' are 'False'. Set one of them to \"\n",
    "                                         \"'True' to use Elmo, or do not provide an Elmo object upon construction.\")\n",
    "            # Check that the number of flags set is equal to the num_output_representations of the Elmo object\n",
    "            # pylint: disable=protected-access,too-many-format-args\n",
    "            if len(self._elmo._scalar_mixes) != self._num_elmo_layers:\n",
    "                raise ConfigurationError(\"Elmo object has num_output_representations=%s, but this does not \"\n",
    "                                         \"match the number of use_*_elmo flags set to true. use_input_elmo \"\n",
    "                                         \"is %s, and use_integrator_output_elmo is %s\".format(\n",
    "                                                 str(len(self._elmo._scalar_mixes)),\n",
    "                                                 str(self._use_input_elmo),\n",
    "                                                 str(self._use_integrator_output_elmo)))\n",
    "\n",
    "        # Calculate combined integrator output dim, taking into account elmo\n",
    "        if self._use_integrator_output_elmo:\n",
    "            self._combined_integrator_output_dim = (self._integrator.get_output_dim() +\n",
    "                                                    self._elmo.get_output_dim())\n",
    "        else:\n",
    "            self._combined_integrator_output_dim = self._integrator.get_output_dim()\n",
    "\n",
    "        self._self_attentive_pooling_projection = nn.Linear(\n",
    "                self._combined_integrator_output_dim, 1)\n",
    "        self._output_layer = output_layer\n",
    "\n",
    "        if self._use_input_elmo:\n",
    "            check_dimensions_match(text_field_embedder.get_output_dim() +\n",
    "                                   self._elmo.get_output_dim(),\n",
    "                                   self._pre_encode_feedforward.get_input_dim(),\n",
    "                                   \"text field embedder output dim + ELMo output dim\",\n",
    "                                   \"Pre-encoder feedforward input dim\")\n",
    "        else:\n",
    "            check_dimensions_match(text_field_embedder.get_output_dim(),\n",
    "                                   self._pre_encode_feedforward.get_input_dim(),\n",
    "                                   \"text field embedder output dim\",\n",
    "                                   \"Pre-encoder feedforward input dim\")\n",
    "\n",
    "        check_dimensions_match(self._pre_encode_feedforward.get_output_dim(),\n",
    "                               self._encoder.get_input_dim(),\n",
    "                               \"Pre-encoder feedforward output dim\",\n",
    "                               \"Encoder input dim\")\n",
    "        check_dimensions_match(self._encoder.get_output_dim() * 3,\n",
    "                               self._integrator.get_input_dim(),\n",
    "                               \"Encoder output dim * 3\",\n",
    "                               \"Integrator input dim\")\n",
    "        if self._use_integrator_output_elmo:\n",
    "            check_dimensions_match(self._combined_integrator_output_dim * 4,\n",
    "                                   self._output_layer.get_input_dim(),\n",
    "                                   \"(Integrator output dim + ELMo output dim) * 4\",\n",
    "                                   \"Output layer input dim\")\n",
    "        else:\n",
    "            check_dimensions_match(self._integrator.get_output_dim() * 4,\n",
    "                                   self._output_layer.get_input_dim(),\n",
    "                                   \"Integrator output dim * 4\",\n",
    "                                   \"Output layer input dim\")\n",
    "\n",
    "        check_dimensions_match(self._output_layer.get_output_dim(),\n",
    "                               self._num_classes,\n",
    "                               \"Output layer output dim\",\n",
    "                               \"Number of classes.\")\n",
    "\n",
    "        self.metrics = {            \n",
    "            \"hit_5\": HitAtK(5),\n",
    "            \"hit_10\": HitAtK(10),\n",
    "            \"hit_100\": HitAtK(100)\n",
    "        }\n",
    "        self.loss = torch.nn.BCEWithLogitsLoss(pos_weight = torch.ones(241)*10)\n",
    "        initializer(self)\n",
    "\n",
    "    @overrides\n",
    "    def forward(self,  # type: ignore\n",
    "                tokens: Dict[str, torch.LongTensor],\n",
    "                label: torch.LongTensor = None) -> Dict[str, torch.Tensor]:\n",
    "        # pylint: disable=arguments-differ\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens : Dict[str, torch.LongTensor], required\n",
    "            The output of ``TextField.as_array()``.\n",
    "        label : torch.LongTensor, optional (default = None)\n",
    "            A variable representing the label for each instance in the batch.\n",
    "        Returns\n",
    "        -------\n",
    "        An output dictionary consisting of:\n",
    "        class_probabilities : torch.FloatTensor\n",
    "            A tensor of shape ``(batch_size, num_classes)`` representing a\n",
    "            distribution over the label classes for each instance.\n",
    "        loss : torch.FloatTensor, optional\n",
    "            A scalar loss to be optimised.\n",
    "        \"\"\"\n",
    "        text_mask = util.get_text_field_mask(tokens).float()\n",
    "        # Pop elmo tokens, since elmo embedder should not be present.\n",
    "        elmo_tokens = tokens.pop(\"elmo\", None)\n",
    "        if tokens:\n",
    "            embedded_text = self._text_field_embedder(tokens)\n",
    "        else:\n",
    "            # only using \"elmo\" for input\n",
    "            embedded_text = None\n",
    "\n",
    "        # Add the \"elmo\" key back to \"tokens\" if not None, since the tests and the\n",
    "        # subsequent training epochs rely not being modified during forward()\n",
    "        if elmo_tokens is not None:\n",
    "            tokens[\"elmo\"] = elmo_tokens\n",
    "\n",
    "        # Create ELMo embeddings if applicable\n",
    "        if self._elmo:\n",
    "            if elmo_tokens is not None:\n",
    "                elmo_representations = self._elmo(elmo_tokens)[\"elmo_representations\"]\n",
    "                # Pop from the end is more performant with list\n",
    "                if self._use_integrator_output_elmo:\n",
    "                    integrator_output_elmo = elmo_representations.pop()\n",
    "                if self._use_input_elmo:\n",
    "                    input_elmo = elmo_representations.pop()\n",
    "                assert not elmo_representations\n",
    "            else:\n",
    "                raise ConfigurationError(\n",
    "                        \"Model was built to use Elmo, but input text is not tokenized for Elmo.\")\n",
    "\n",
    "        if self._use_input_elmo:\n",
    "            if embedded_text is not None:\n",
    "                embedded_text = torch.cat([embedded_text, input_elmo], dim=-1)\n",
    "            else:\n",
    "                embedded_text = input_elmo\n",
    "\n",
    "        dropped_embedded_text = self._embedding_dropout(embedded_text)\n",
    "        pre_encoded_text = self._pre_encode_feedforward(dropped_embedded_text)\n",
    "        encoded_tokens = self._encoder(pre_encoded_text, text_mask)\n",
    "\n",
    "        # Compute biattention. This is a special case since the inputs are the same.\n",
    "        attention_logits = encoded_tokens.bmm(encoded_tokens.permute(0, 2, 1).contiguous())\n",
    "        attention_weights = util.masked_softmax(attention_logits, text_mask)\n",
    "        encoded_text = util.weighted_sum(encoded_tokens, attention_weights)\n",
    "\n",
    "        # Build the input to the integrator\n",
    "        integrator_input = torch.cat([encoded_tokens,\n",
    "                                      encoded_tokens - encoded_text,\n",
    "                                      encoded_tokens * encoded_text], 2)\n",
    "        integrated_encodings = self._integrator(integrator_input, text_mask)\n",
    "\n",
    "        # Concatenate ELMo representations to integrated_encodings if specified\n",
    "        if self._use_integrator_output_elmo:\n",
    "            integrated_encodings = torch.cat([integrated_encodings,\n",
    "                                              integrator_output_elmo], dim=-1)\n",
    "\n",
    "        # Simple Pooling layers\n",
    "        max_masked_integrated_encodings = util.replace_masked_values(\n",
    "                integrated_encodings, text_mask.unsqueeze(2), -1e7)\n",
    "        max_pool = torch.max(max_masked_integrated_encodings, 1)[0]\n",
    "        min_masked_integrated_encodings = util.replace_masked_values(\n",
    "                integrated_encodings, text_mask.unsqueeze(2), +1e7)\n",
    "        min_pool = torch.min(min_masked_integrated_encodings, 1)[0]\n",
    "        mean_pool = torch.sum(integrated_encodings, 1) / torch.sum(text_mask, 1, keepdim=True)\n",
    "\n",
    "        # Self-attentive pooling layer\n",
    "        # Run through linear projection. Shape: (batch_size, sequence length, 1)\n",
    "        # Then remove the last dimension to get the proper attention shape (batch_size, sequence length).\n",
    "        self_attentive_logits = self._self_attentive_pooling_projection(\n",
    "                integrated_encodings).squeeze(2)\n",
    "        self_weights = util.masked_softmax(self_attentive_logits, text_mask)\n",
    "        self_attentive_pool = util.weighted_sum(integrated_encodings, self_weights)\n",
    "\n",
    "        pooled_representations = torch.cat([max_pool, min_pool, mean_pool, self_attentive_pool], 1)\n",
    "        pooled_representations_dropped = self._integrator_dropout(pooled_representations)\n",
    "\n",
    "        logits = self._output_layer(pooled_representations_dropped)\n",
    "        class_probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "        output_dict = {'logits': logits, 'class_probabilities': class_probabilities}\n",
    "        if label is not None:\n",
    "            loss = self.loss(logits, label)\n",
    "            for metric in self.metrics.values():\n",
    "                metric(logits, label)\n",
    "            output_dict[\"loss\"] = loss\n",
    "\n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def decode(self, output_dict: Dict[str, torch.Tensor]) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Does a simple argmax over the class probabilities, converts indices to string labels, and\n",
    "        adds a ``\"label\"`` key to the dictionary with the result.\n",
    "        \"\"\"\n",
    "        predictions = output_dict[\"class_probabilities\"].cpu().data.numpy()\n",
    "        argmax_indices = numpy.argmax(predictions, axis=-1)\n",
    "        labels = [self.vocab.get_token_from_index(x, namespace=\"labels\")\n",
    "                  for x in argmax_indices]\n",
    "        output_dict['label'] = labels\n",
    "        return output_dict\n",
    "\n",
    "    @overrides\n",
    "    def get_metrics(self, reset: bool = False) -> Dict[str, float]:\n",
    "        return {metric_name: metric.get_metric(reset) for metric_name, metric in self.metrics.items()}\n",
    "\n",
    "    # The FeedForward vs Maxout logic here requires a custom from_params.\n",
    "    @classmethod\n",
    "    def from_params(cls, vocab: Vocabulary, params: Params) -> 'BiattentiveClassificationNetwork':  # type: ignore\n",
    "        # pylint: disable=arguments-differ\n",
    "        embedder_params = params.pop(\"text_field_embedder\")\n",
    "        text_field_embedder = TextFieldEmbedder.from_params(vocab=vocab, params=embedder_params)\n",
    "        embedding_dropout = params.pop(\"embedding_dropout\")\n",
    "        pre_encode_feedforward = FeedForward.from_params(params.pop(\"pre_encode_feedforward\"))\n",
    "        encoder = Seq2SeqEncoder.from_params(params.pop(\"encoder\"))\n",
    "        integrator = Seq2SeqEncoder.from_params(params.pop(\"integrator\"))\n",
    "        integrator_dropout = params.pop(\"integrator_dropout\")\n",
    "\n",
    "        output_layer_params = params.pop(\"output_layer\")\n",
    "        if \"activations\" in output_layer_params:\n",
    "            output_layer = FeedForward.from_params(output_layer_params)\n",
    "        else:\n",
    "            output_layer = Maxout.from_params(output_layer_params)\n",
    "\n",
    "        elmo = params.pop(\"elmo\", None)\n",
    "        if elmo is not None:\n",
    "            elmo = Elmo.from_params(elmo)\n",
    "        use_input_elmo = params.pop_bool(\"use_input_elmo\", False)\n",
    "        use_integrator_output_elmo = params.pop_bool(\"use_integrator_output_elmo\", False)\n",
    "\n",
    "        initializer = InitializerApplicator.from_params(params.pop('initializer', []))\n",
    "        regularizer = RegularizerApplicator.from_params(params.pop('regularizer', []))\n",
    "        params.assert_empty(cls.__name__)\n",
    "\n",
    "        return cls(vocab=vocab,\n",
    "                   text_field_embedder=text_field_embedder,\n",
    "                   embedding_dropout=embedding_dropout,\n",
    "                   pre_encode_feedforward=pre_encode_feedforward,\n",
    "                   encoder=encoder,\n",
    "                   integrator=integrator,\n",
    "                   integrator_dropout=integrator_dropout,\n",
    "                   output_layer=output_layer,\n",
    "                   elmo=elmo,\n",
    "                   use_input_elmo=use_input_elmo,\n",
    "                   use_integrator_output_elmo=use_integrator_output_elmo,\n",
    "                   initializer=initializer,\n",
    "                   regularizer=regularizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_indexers = {\"glove_tokens\": SingleIdTokenIndexer(namespace=\"glove_tokens\",lowercase_tokens=True),\n",
    "                  \"conceptnet_tokens\": SingleIdTokenIndexer(namespace=\"conceptnet_tokens\",lowercase_tokens=True),\n",
    "                  \"fasttext_tokens\": SingleIdTokenIndexer(namespace=\"fasttext_tokens\",lowercase_tokens=True)}\n",
    "reader = EtdAbstractReader(token_indexers=token_indexers,\n",
    "                                lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:02, 37.30it/s]\n",
      "94it [00:01, 53.48it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = reader.read(cached_path(\n",
    "    \"/misc/projdata3/info_fil/finance/simon_test/ETD_cataloguing/allennlp-test/etd_debug.json\"\n",
    "))\n",
    "validation_dataset = reader.read(cached_path(\n",
    "    \"/misc/projdata3/info_fil/finance/simon_test/ETD_cataloguing/allennlp-test/etd_debug.json\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:01<00:00, 155.56it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset + validation_dataset, min_count={\"glove_tokens\": 1,\n",
    "                                                                                 \"concentnet_tokens\":1,\n",
    "                                                                                 \"fasttext_tokens\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400000it [00:02, 156456.21it/s]\n",
      "417194it [00:03, 108552.17it/s]\n",
      "1999995it [00:14, 136992.37it/s]\n"
     ]
    }
   ],
   "source": [
    "file_url = \"/uac/spc/proj/fpredict/finance/ETD_cataloguing/allennlp-test/word_vector/glove/glove.6B.100d.txt\"\n",
    "glove_embedding = _read_pretrained_embeddings_file(file_uri=file_url,\n",
    "                                                   embedding_dim=100,\n",
    "                                                   vocab=vocab,\n",
    "                                                   namespace=\"glove_tokens\")\n",
    "glove_embedding = Embedding(num_embeddings=vocab.get_vocab_size('glove_tokens'),\n",
    "                            embedding_dim=100,\n",
    "                            weight=glove_embedding,\n",
    "                            trainable=False)\n",
    "\n",
    "file_url = \"/uac/spc/proj/fpredict/finance/ETD_cataloguing/allennlp-test/word_vector/conceptnet/numberbatch-en-17.06.txt\"\n",
    "conceptnet_embedding = _read_pretrained_embeddings_file(file_uri=file_url,\n",
    "                                                   embedding_dim=300,\n",
    "                                                   vocab=vocab,\n",
    "                                                   namespace=\"conceptnet_tokens\")\n",
    "conceptnet_embedding = Embedding(num_embeddings=vocab.get_vocab_size('conceptnet_tokens'),\n",
    "                                 embedding_dim=300,\n",
    "                                 weight=conceptnet_embedding,\n",
    "                                 trainable=False)\n",
    "\n",
    "file_url = \"/uac/spc/proj/fpredict/finance/ETD_cataloguing/allennlp-test/word_vector/fasttext/crawl-300d-2M.vec\"\n",
    "fasttext_embedding = _read_pretrained_embeddings_file(file_uri=file_url,\n",
    "                                                   embedding_dim=300,\n",
    "                                                   vocab=vocab,\n",
    "                                                   namespace=\"fasttext_tokens\")\n",
    "fasttext_embedding = Embedding(num_embeddings=vocab.get_vocab_size('fasttext_tokens'),\n",
    "                               embedding_dim=300,\n",
    "                               weight=fasttext_embedding,\n",
    "                               trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projdata3/info_fil/finance/simon_test/anaconda2/envs/allennlp-acc-grad/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "text_field_embedder = BasicTextFieldEmbedder({\"glove_tokens\":glove_embedding,\n",
    "                                              \"conceptnet_tokens\":conceptnet_embedding,\n",
    "                                              \"fasttext_tokens\":fasttext_embedding})\n",
    "\n",
    "# model = EtdBCN(vocab=vocab,\n",
    "#                text_field_embedder=text_field_embedder,\n",
    "#                title_text_encoder=PytorchSeq2SeqWrapper(torch.nn.GRU(input_size=700,\n",
    "#                                                                      hidden_size=400,\n",
    "#                                                                      num_layers=1,\n",
    "#                                                                      dropout=0.2,\n",
    "#                                                                      bidirectional=True,\n",
    "#                                                                      batch_first=True)),\n",
    "#                abstract_text_encoder=PytorchSeq2SeqWrapper(torch.nn.GRU(input_size=700,\n",
    "#                                                                      hidden_size=400,\n",
    "#                                                                      num_layers=1,\n",
    "#                                                                      dropout=0.2,\n",
    "#                                                                      bidirectional=True,\n",
    "#                                                                      batch_first=True)),\n",
    "#                bi_attention_encoder=BiAttentionEncoder(input_dim=800,\n",
    "#                                                        integrator_x=PytorchSeq2SeqWrapper(torch.nn.GRU(input_size=2400,\n",
    "#                                                                      hidden_size=1200,\n",
    "#                                                                      num_layers=1,\n",
    "#                                                                      dropout=0.2,\n",
    "#                                                                      bidirectional=True,\n",
    "#                                                                      batch_first=True)),\n",
    "#                                                        integrator_y=PytorchSeq2SeqWrapper(torch.nn.GRU(input_size=2400,\n",
    "#                                                                      hidden_size=1200,\n",
    "#                                                                      num_layers=1,\n",
    "#                                                                      dropout=0.2,\n",
    "#                                                                      bidirectional=True,\n",
    "#                                                                      batch_first=True)),\n",
    "#                                                        integrator_dropout=0.2,\n",
    "#                                                        combination=\"x,y\"),\n",
    "#                classifier_feedforward=FeedForward(input_dim=4800,\n",
    "#                                                   num_layers=2,\n",
    "#                                                   hidden_dims=[4800,241],\n",
    "#                                                   activations=[Activation.by_name(\"relu\")(),Activation.by_name(\"linear\")()]),\n",
    "#                use_positional_encoding=True)\n",
    "\n",
    "model = BiattentiveClassificationNetwork(vocab=vocab,\n",
    "                                         text_field_embedder=text_field_embedder,\n",
    "                                         embedding_dropout=0.0,\n",
    "                                         pre_encode_feedforward=FeedForward(input_dim=700,\n",
    "                                                                            num_layers=1,\n",
    "                                                                            hidden_dims=[700],\n",
    "                                                                            activations=[Activation.by_name(\"relu\")()]),\n",
    "                                         encoder=PytorchSeq2SeqWrapper(torch.nn.GRU(input_size=700,\n",
    "                                                                       hidden_size=400,\n",
    "                                                                       num_layers=1,\n",
    "                                                                       dropout=0.2,\n",
    "                                                                       bidirectional=True,\n",
    "                                                                       batch_first=True)),\n",
    "                                         integrator=PytorchSeq2SeqWrapper(torch.nn.GRU(input_size=2400,\n",
    "                                                                          hidden_size=600,\n",
    "                                                                          num_layers=1,\n",
    "                                                                          dropout=0.2,\n",
    "                                                                          bidirectional=True,\n",
    "                                                                          batch_first=True)),\n",
    "                                         integrator_dropout=0.2,\n",
    "                                         output_layer=FeedForward(input_dim=4800,\n",
    "                                                      num_layers=2,\n",
    "                                                      hidden_dims=[4800,241],\n",
    "                                                      activations=[Activation.by_name(\"relu\")(),Activation.by_name(\"linear\")()]),\n",
    "                                         elmo=None\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "iterator = BucketIterator(batch_size=2, sorting_keys=[[\"tokens\", \"num_tokens\"]])\n",
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  iterator=iterator,\n",
    "                  train_dataset=train_dataset,\n",
    "                  validation_dataset=validation_dataset,\n",
    "                  patience=10,\n",
    "                  grad_clipping=5.0,\n",
    "                  num_epochs=100,\n",
    "                  num_batches_before_step=16,\n",
    "                  cuda_device=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "hit_5: 0.021910, hit_10: 0.040881, hit_100: 0.284878, loss: 0.714026 ||: 100%|██████████| 47/47 [00:15<00:00,  4.12it/s]\n",
      "hit_5: 0.049215, hit_10: 0.080066, hit_100: 0.456054, loss: 0.424645 ||: 100%|██████████| 47/47 [00:05<00:00,  4.61it/s]\n",
      "hit_5: 0.040350, hit_10: 0.065527, hit_100: 0.408536, loss: 0.450399 ||: 100%|██████████| 47/47 [00:10<00:00,  4.60it/s]\n",
      "hit_5: 0.066413, hit_10: 0.093718, hit_100: 0.434068, loss: 0.448376 ||: 100%|██████████| 47/47 [00:06<00:00,  4.16it/s]\n",
      "hit_5: 0.056130, hit_10: 0.086626, hit_100: 0.411196, loss: 0.451944 ||: 100%|██████████| 47/47 [00:10<00:00,  4.41it/s]\n",
      "hit_5: 0.056130, hit_10: 0.091945, hit_100: 0.452077, loss: 0.410705 ||: 100%|██████████| 47/47 [00:03<00:00,  5.88it/s]\n",
      "hit_5: 0.051342, hit_10: 0.072442, hit_100: 0.445871, loss: 0.407302 ||: 100%|██████████| 47/47 [00:08<00:00,  5.39it/s]\n",
      "hit_5: 0.050811, hit_10: 0.092503, hit_100: 0.487639, loss: 0.373566 ||: 100%|██████████| 47/47 [00:03<00:00,  8.70it/s]\n",
      "hit_5: 0.045137, hit_10: 0.077786, hit_100: 0.354205, loss: 0.385974 ||: 100%|██████████| 47/47 [00:07<00:00,  6.28it/s]\n",
      "hit_5: 0.059954, hit_10: 0.087969, hit_100: 0.503723, loss: 0.376770 ||: 100%|██████████| 47/47 [00:03<00:00,  8.31it/s]\n",
      "hit_5: 0.059422, hit_10: 0.076976, hit_100: 0.440248, loss: 0.383180 ||: 100%|██████████| 47/47 [00:07<00:00,  5.25it/s]\n",
      "hit_5: 0.057827, hit_10: 0.101444, hit_100: 0.511854, loss: 0.371823 ||: 100%|██████████| 47/47 [00:03<00:00,  6.79it/s]\n",
      "hit_5: 0.051621, hit_10: 0.089311, hit_100: 0.453318, loss: 0.377798 ||: 100%|██████████| 47/47 [00:08<00:00,  5.64it/s]\n",
      "hit_5: 0.075557, hit_10: 0.108891, hit_100: 0.542857, loss: 0.367190 ||: 100%|██████████| 47/47 [00:04<00:00,  6.52it/s]\n",
      "hit_5: 0.062259, hit_10: 0.099671, hit_100: 0.487006, loss: 0.371108 ||: 100%|██████████| 47/47 [00:09<00:00,  5.16it/s]\n",
      "hit_5: 0.064387, hit_10: 0.115628, hit_100: 0.568389, loss: 0.363646 ||: 100%|██████████| 47/47 [00:03<00:00,  6.11it/s]\n",
      "hit_5: 0.054889, hit_10: 0.097898, hit_100: 0.472644, loss: 0.368121 ||: 100%|██████████| 47/47 [00:09<00:00,  3.07it/s]\n",
      "hit_5: 0.085917, hit_10: 0.120770, hit_100: 0.573176, loss: 0.361466 ||: 100%|██████████| 47/47 [00:05<00:00,  5.53it/s]\n",
      "hit_5: 0.062867, hit_10: 0.106408, hit_100: 0.517680, loss: 0.365218 ||: 100%|██████████| 47/47 [00:10<00:00,  4.05it/s]\n",
      "hit_5: 0.062867, hit_10: 0.120061, hit_100: 0.631332, loss: 0.358201 ||: 100%|██████████| 47/47 [00:04<00:00,  5.66it/s]\n",
      "hit_5: 0.062867, hit_10: 0.125127, hit_100: 0.540907, loss: 0.361773 ||: 100%|██████████| 47/47 [00:10<00:00,  5.89it/s]\n",
      "hit_5: 0.068541, hit_10: 0.139311, hit_100: 0.640198, loss: 0.354707 ||: 100%|██████████| 47/47 [00:04<00:00,  6.77it/s]\n",
      "hit_5: 0.069073, hit_10: 0.135765, hit_100: 0.594985, loss: 0.357322 ||: 100%|██████████| 47/47 [00:10<00:00,  5.10it/s]\n",
      "hit_5: 0.107396, hit_10: 0.149417, hit_100: 0.696049, loss: 0.350154 ||: 100%|██████████| 47/47 [00:05<00:00,  5.27it/s]\n",
      "hit_5: 0.086373, hit_10: 0.133992, hit_100: 0.649949, loss: 0.352818 ||: 100%|██████████| 47/47 [00:09<00:00,  5.22it/s]\n",
      "hit_5: 0.096125, hit_10: 0.178318, hit_100: 0.761120, loss: 0.342561 ||: 100%|██████████| 47/47 [00:04<00:00,  5.11it/s]\n",
      "hit_5: 0.099316, hit_10: 0.163425, hit_100: 0.727786, loss: 0.343625 ||: 100%|██████████| 47/47 [00:11<00:00,  4.76it/s]\n",
      "hit_5: 0.107118, hit_10: 0.197822, hit_100: 0.829737, loss: 0.329802 ||: 100%|██████████| 47/47 [00:04<00:00,  5.69it/s]\n",
      "hit_5: 0.107472, hit_10: 0.180091, hit_100: 0.816084, loss: 0.332128 ||: 100%|██████████| 47/47 [00:09<00:00,  4.10it/s]\n",
      "hit_5: 0.148886, hit_10: 0.248531, hit_100: 0.882852, loss: 0.316972 ||: 100%|██████████| 47/47 [00:04<00:00,  4.78it/s]\n",
      "hit_5: 0.124924, hit_10: 0.227077, hit_100: 0.870694, loss: 0.317633 ||: 100%|██████████| 47/47 [00:10<00:00,  4.98it/s]\n",
      "hit_5: 0.182396, hit_10: 0.258992, hit_100: 0.951672, loss: 0.295245 ||: 100%|██████████| 47/47 [00:05<00:00,  4.41it/s]\n",
      "hit_5: 0.158004, hit_10: 0.240198, hit_100: 0.919934, loss: 0.299457 ||: 100%|██████████| 47/47 [00:09<00:00,  4.72it/s]\n",
      "hit_5: 0.164210, hit_10: 0.251621, hit_100: 0.949113, loss: 0.284712 ||: 100%|██████████| 47/47 [00:03<00:00,  7.08it/s]\n",
      "hit_5: 0.151900, hit_10: 0.252254, hit_100: 0.935816, loss: 0.289952 ||: 100%|██████████| 47/47 [00:08<00:00,  6.10it/s]\n",
      "hit_5: 0.202862, hit_10: 0.309878, hit_100: 0.933511, loss: 0.276470 ||: 100%|██████████| 47/47 [00:03<00:00,  6.79it/s]\n",
      "hit_5: 0.165881, hit_10: 0.247366, hit_100: 0.942376, loss: 0.284810 ||: 100%|██████████| 47/47 [00:08<00:00,  6.38it/s]\n",
      "hit_5: 0.244098, hit_10: 0.387006, hit_100: 0.994681, loss: 0.255387 ||: 100%|██████████| 47/47 [00:03<00:00,  6.97it/s]\n",
      "hit_5: 0.176444, hit_10: 0.299240, hit_100: 0.966489, loss: 0.270408 ||: 100%|██████████| 47/47 [00:09<00:00,  4.02it/s]\n",
      "hit_5: 0.331839, hit_10: 0.468110, hit_100: 0.997340, loss: 0.245941 ||: 100%|██████████| 47/47 [00:04<00:00,  5.09it/s]\n",
      "hit_5: 0.264818, hit_10: 0.367832, hit_100: 0.986702, loss: 0.260427 ||: 100%|██████████| 47/47 [00:08<00:00,  6.38it/s]\n",
      "hit_5: 0.356256, hit_10: 0.508688, hit_100: 0.997340, loss: 0.236704 ||: 100%|██████████| 47/47 [00:02<00:00, 15.79it/s]\n",
      "hit_5: 0.328774, hit_10: 0.465071, hit_100: 0.986702, loss: 0.241173 ||: 100%|██████████| 47/47 [00:07<00:00,  6.98it/s]\n",
      "hit_5: 0.386829, hit_10: 0.570263, hit_100: 1.000000, loss: 0.217246 ||: 100%|██████████| 47/47 [00:03<00:00,  6.95it/s]\n",
      "hit_5: 0.330699, hit_10: 0.460436, hit_100: 1.000000, loss: 0.218964 ||: 100%|██████████| 47/47 [00:09<00:00,  5.18it/s]\n",
      "hit_5: 0.506231, hit_10: 0.686474, hit_100: 1.000000, loss: 0.189401 ||: 100%|██████████| 47/47 [00:03<00:00,  6.40it/s]\n",
      "hit_5: 0.395833, hit_10: 0.531250, hit_100: 1.000000, loss: 0.214348 ||:  17%|█▋        | 8/47 [00:01<00:07,  5.10it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/misc/projdata3/info_fil/finance/simon_test/allennlp/allennlp/training/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mepoch_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m             \u001b[0mtrain_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_before_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validation_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/misc/projdata3/info_fil/finance/simon_test/allennlp/allennlp/training/trainer.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, epoch, num_batches_before_step)\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfor_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_batches_before_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_batches_before_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projdata3/info_fil/finance/simon_test/anaconda2/envs/allennlp-acc-grad/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/projdata3/info_fil/finance/simon_test/anaconda2/envs/allennlp-acc-grad/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
